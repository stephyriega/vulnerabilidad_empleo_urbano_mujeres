{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e36991f",
   "metadata": {},
   "source": [
    "# Thesis project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfdec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas openpyxl\n",
    "# !pip install graphviz pretty_confusion_matrix pydotplus shap kneed\n",
    "# !pip install scikit-learn==1.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445d515c",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007196c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }a\n",
    "</style>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75445578",
   "metadata": {},
   "outputs": [],
   "source": [
    "1#general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statistics\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.stats import t\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages for Lasso & Data Splitting\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300915ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pylab as pyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant packages for \n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9906771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import  confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c94445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e4b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn import pipeline as pl \n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a289d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import StratifiedGroupKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c6211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# from pretty_confusion_matrix import pp_matrix_from_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae4f6ef",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b727fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Y DataFrame from CSV\n",
    "data_Y_s= pd.read_csv('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\3_datos\\\\data_Y_s_271223_1.csv')\n",
    "\n",
    "# Import X DataFrame from CSV\n",
    "data_m = pd.read_csv('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\3_datos\\\\data_m_271223_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0297bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming data_Y_s is a pandas DataFrame and deg_desempleo is a column in that DataFrame\n",
    "value_counts_percent = data_Y_s['ano_19'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Percentage of each value in 'deg_desemp':\")\n",
    "print(value_counts_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea571397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_Y_s=data_Y_s1[:1000]\n",
    "# data_m=data_m1[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be37ef8",
   "metadata": {},
   "source": [
    "**Pregunta: i) deberia exportar la matriz de correlacion? o por partes (si alcanza tiempo)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2d15ad",
   "metadata": {},
   "source": [
    "## CV Stratified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e4939b",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57a0ba6",
   "metadata": {},
   "source": [
    "Here, we split the observations in 2 samples: the training set and the test set. Let's remember that our test set is composed from data collected between 2016 to 2019, and we are going test on a data set componsed of a little bit of each year. However, we are going to predict in 2020 and compare with what really happened. \n",
    "\n",
    "To begin with, we must create the X and y that are going to pass throught data splitting into training and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_main_pre =  data_m.drop(['num_panel'], axis=1)\n",
    "y_main_pre = data_Y_s.loc[:,('deg_desemp', 'ano_19')]\n",
    "groups_pre = data_m[['ano_reg', 'ano_19']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472de99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_main_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a1c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an empty list to store the names of continuous variables\n",
    "# continuous_cols = []\n",
    "\n",
    "# # Set a threshold for the number of unique values to distinguish categorical from continuous variables\n",
    "# unique_value_threshold = 8\n",
    "\n",
    "# # Iterate through the columns and identify continuous variables\n",
    "# for col in x_main_pre.columns:\n",
    "#     # Check if the column is numeric\n",
    "#     if x_main_pre[col].dtype in [int, float]:\n",
    "#         # Check the number of unique values in the column\n",
    "#         num_unique_values = x_main_pre[col].nunique()\n",
    "        \n",
    "#         # Consider it as continuous only if the number of unique values is above the threshold\n",
    "#         if num_unique_values > unique_value_threshold:\n",
    "#             continuous_cols.append(col)\n",
    "        \n",
    "#         # Print column name and data type\n",
    "#         print(f\"{col}: {x_main_pre[col].dtype}\")\n",
    "\n",
    "# # Now 'continuous_cols' will contain the names of continuous variables in the DataFrame\n",
    "# print(\"Continuous Variables:\", continuous_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_col_total = [\n",
    "    'y_pri_dep', 'y_pri_indep', 'y_pri', 'y_sec_dep', 'y_sec_ind', 'y_sec', 'y_mkt',\n",
    "    'pobre2', 'gpcm', 'ingtrabw', 'ipcr_0', 'ipcr_1', 'ipcr_2', 'ipcr_3', 'ipcr_4',\n",
    "    'ipcr_5', 'ipcr_6', 'ipcr_7', 'ipcr_8', 'ipcr_9', 'ipcr_10', 'ipcr_11', 'ipcr_12',\n",
    "    'ipcr_13', 'ipcr_14', 'ipcr_15', 'ipcr_16', 'ipcr_17', 'ipcr_18', 'ipcr_19', 'ipcr_20',\n",
    "    'gpgru1', 'gpgru2', 'gpgru3', 'gpgru4', 'gpgru5', 'gpgru6', 'gpgru7', 'gpgru8', 'gpgru9',\n",
    "    'gpgru10', 'p104a', 'i1172_01', 'i1172_02', 'i1173_01', 'i1173_02', 'p208a', 'p512a', 'p513t',\n",
    "    'n_edad_prim', 'n_edad_sec', 'n_edad_esc', 'n_matr_prim', 'n_matr_sec', 'n_matr_esc'\n",
    "    \n",
    "    ,'p203a'\n",
    "]\n",
    "\n",
    "f_cont_total = list(set(continous_col_total).intersection(x_main_pre.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0331e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_i = x_main_pre.loc[x_main_pre['ano_19'] != 1].drop(['ano_19'], axis=1)\n",
    "y_train = y_main_pre.loc[y_main_pre['ano_19'] != 1].drop(['ano_19'], axis=1)\n",
    "\n",
    "x_test_i = x_main_pre.loc[x_main_pre['ano_19'] == 1].drop(['ano_19'], axis=1)\n",
    "y_test  = y_main_pre.loc[y_main_pre['ano_19'] == 1].drop(['ano_19'], axis=1)\n",
    "\n",
    "groups = groups_pre.loc[x_main_pre['ano_19'] != 1].drop(['ano_19'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bfda9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_i['gpgru7'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c2c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract continuous and non-continuous columns from x_train_i\n",
    "# x_train_continuous = x_train_i[f_cont_total]\n",
    "# x_train_non_continuous = x_train_i.drop(columns=f_cont_total)\n",
    "# x_train_continuous.isnull().sum()\n",
    "# # Scale the continuous columns\n",
    "# std = StandardScaler()\n",
    "\n",
    "# scaled_continuous = pd.DataFrame(std.fit_transform(x_train_continuous))\n",
    "# scaled_continuous                             \n",
    "# #scaled_continuous.isnull().sum()\n",
    "# # Create a new DataFrame with scaled continuous columns and non-continuous columns\n",
    "# x_train = pd.concat([scaled_continuous, x_train_non_continuous], axis=1)\n",
    "# x_train\n",
    "# x_train['gpgru7'].isnull().sum()\n",
    "# duplicated_columns = x_train.columns[x_train.columns.duplicated()]\n",
    "# print(\"Duplicated columns: \", duplicated_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e1dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(scale(x_train_i), columns=x_train_i.columns)\n",
    "#y_train = pd.DataFrame(scaler.fit_transform(y_train_i), columns=y_train_i.columns)\n",
    "\n",
    "x_test = pd.DataFrame(scale(x_test_i), columns=x_test_i.columns)\n",
    "#y_test  = pd.DataFrame(scaler.fit_transform(y_test_i), columns=y_test_i.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68352c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57aacbf",
   "metadata": {},
   "source": [
    "Let's remember the train set is going to be used to train the model (by simulating a lot of samples using the CV) and the test set is going to be used to test the model out-of-sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([x_train, x_test], ignore_index=True)\n",
    "Y = pd.concat([y_train, y_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b247d5",
   "metadata": {},
   "source": [
    "We have 193 variables in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2037ec",
   "metadata": {},
   "source": [
    "For the Stratified Group CV, we need to determine the variable groups that the code will interpret as groups of the x variables and the class will depend on the \"groups\" of y (2 classes: employment and nonemployment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bfee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = x_train.isna().sum().sort_values()\n",
    "n = 15  # Number of last values you want to print\n",
    "last_n_values = missing_counts[-n:]\n",
    "\n",
    "print(last_n_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cde172",
   "metadata": {},
   "source": [
    "## Estimations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38137bcf",
   "metadata": {},
   "source": [
    "### Choosing the optimal lambda using grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa1efd4",
   "metadata": {},
   "source": [
    "We establish a a grid of posibles values for $\\lambda$ using grid search. It starts at the value of 0 and then we started trying with different maximun values, as well as differente intervals between the values (that depend on the number of $\\lambda$ we are planning to incluide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determining a set of lambdas to test wich one is the best\n",
    "l_min = 0.001\n",
    "l_max = 500\n",
    "l_num = 1000\n",
    "l_num_div=np.int(l_num/2)\n",
    "lambdas = np.linspace(l_min,l_max, l_num)\n",
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_lambda=np.std(lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf62cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_seed=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c6636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_num_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ae84f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flaml import AutoML\n",
    "# y_train_array = y_train.values\n",
    "# # Define the pipeline with a search space for hyperparameters\n",
    "# def get_pipeline(under_sampler__sampling_strategy, logistic_regression__C):\n",
    "#     return make_pipeline(\n",
    "#         RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42),\n",
    "#         LogisticRegression(C=C, penalty='l1', solver='liblinear', random_state=42)\n",
    "#     )\n",
    "\n",
    "# # Specify the hyperparameter search space\n",
    "# param_space = {\n",
    "#     'under_sampler__sampling_strategy': ('auto', 0.5, 0.8),\n",
    "#     'logistic_regression__C': (0.001, 0.01, 0.1, 1, 10),\n",
    "# }\n",
    "\n",
    "# # Create an AutoML instance\n",
    "# automl = AutoML()\n",
    "\n",
    "# # Run FLAML to search for the best hyperparameters\n",
    "# automl.fit(X_train=x_train, y_train=y_train_array, task='classification', estimator_list=[('pipeline', get_pipeline, param_space)])\n",
    "\n",
    "# # Print the best pipeline configuration and its performance\n",
    "# print(automl.best_estimator)\n",
    "# print(automl.best_config)\n",
    "# print(automl.best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0141706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d8826",
   "metadata": {},
   "source": [
    "## 1. Logit penalizado con Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c5e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scores = []\n",
    "testing_scores = []\n",
    "coefficients = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, i in enumerate(lambdas):\n",
    "    # Create a pipeline with RandomUnderSampler and LogisticRegression with L1 penalty\n",
    "    reg = pl.make_pipeline(\n",
    "        RandomUnderSampler(random_state=your_seed),\n",
    "        LogisticRegression(C=1/i, penalty='l1', solver='liblinear', random_state=your_seed)\n",
    "    )\n",
    "    \n",
    "    reg.fit(x_train, y_train)\n",
    "    \n",
    "    skf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=your_seed)\n",
    "    results = cross_validate(reg, x_train, y_train, groups=groups, cv=skf, scoring=\"roc_auc\", return_train_score=True)\n",
    "    \n",
    "    # Append the training and testing score means to the lists\n",
    "    training_scores.append(results['train_score'].mean())\n",
    "    testing_scores.append(results['test_score'].mean())\n",
    "    \n",
    "    # Capture the coefficients\n",
    "    coefficients.append(reg.named_steps['logisticregression'].coef_.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f37e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence intervals\n",
    "\n",
    "# Number of bootstrap samples\n",
    "num_bootstrap_samples = 1000\n",
    "\n",
    "# Initialize an array to store bootstrap samples for \n",
    "bootstrap_samples_test = np.zeros((num_bootstrap_samples, len(testing_scores)))\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(num_bootstrap_samples):\n",
    "    # Resample with replacement\n",
    "    bootstrap_sample_test = resample(testing_scores)\n",
    "    bootstrap_samples_test[i, :] = bootstrap_sample_test\n",
    "    \n",
    "\n",
    "# Initialize an array to store bootstrap samples\n",
    "bootstrap_samples_tra = np.zeros((num_bootstrap_samples, len(training_scores)))\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(num_bootstrap_samples):\n",
    "    # Resample with replacement\n",
    "    bootstrap_sample_tra = resample(training_scores)\n",
    "    bootstrap_samples_tra[i, :] = bootstrap_sample_tra\n",
    "\n",
    "    \n",
    "\n",
    "# Calculate mean and percentiles for confidence intervals\n",
    "mean_scores_test = np.mean(bootstrap_samples_test, axis=0)\n",
    "lower_bound_test = np.percentile(bootstrap_samples_test, 2.5, axis=0)\n",
    "upper_bound_test = np.percentile(bootstrap_samples_test, 97.5, axis=0)\n",
    "\n",
    "# Calculate mean and percentiles for confidence intervals\n",
    "mean_scores_tra = np.mean(bootstrap_samples_tra, axis=0)\n",
    "lower_bound_tra = np.percentile(bootstrap_samples_tra, 2.5, axis=0)\n",
    "upper_bound_tra = np.percentile(bootstrap_samples_tra, 97.5, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03d0b6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "\n",
    "#plt.plot(np.std(testing_scores)+(testing_scores), 'bo-', label=r'Intervalos de confianza', color=\"darkblue\", marker = \"o\",markersize = 8,  alpha=0.6, linewidth=3)\n",
    "plt.plot(lambdas, testing_scores, label=r'Muestra de validación', color=\"darkred\", marker = \"o\", markersize=8, alpha=0.6, linewidth=3)\n",
    "#plt.plot((testing_scores)-np.std(testing_scores), 'bo-', marker = \"o\", color=\"darkblue\", alpha=0.6, linewidth=3)\n",
    "plt.fill_between(lambdas, lower_bound_test, upper_bound_test, color='lightcoral', alpha=0.3)\n",
    "\n",
    "\n",
    "#plt.plot(np.std(training_scores)+(training_scores), 'bo-', color=\"darkblue\", marker = \"o\",markersize = 8,  alpha=0.6, linewidth=3)\n",
    "plt.plot(lambdas, training_scores, label=r'Muestra de entrenamiento', color=\"green\", marker = \"o\", markersize=8, alpha=0.6, linewidth=3)\n",
    "#plt.plot((training_scores)-np.std(training_scores), 'bo-', marker = \"o\", color=\"darkblue\", alpha=0.6, linewidth=3)\n",
    "plt.fill_between(lambdas, lower_bound_tra, upper_bound_tra, color='lightgreen', alpha=0.3)\n",
    "\n",
    "plt.xlabel('Valor del lambda'); plt.ylabel('Valor promedio de AUC ROC')\n",
    "plt.xlim(0,215)\n",
    "plt.ylim(0.4,0.7)\n",
    "plt.title('Valor promedio del $AUC ROC$ en las muestras de entrenamiento y validación según lambda')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\4_grafico\\\\precision_1_lambda_completo_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hallamos el lambda que maximiza el precision\n",
    "df_lam = pd.DataFrame(testing_scores, columns=['metric'])\n",
    "df_lam['lambda'] = (lambdas)\n",
    "lamb_opt = df_lam.loc[df_lam['metric'].idxmax()]\n",
    "\n",
    "lambda_optimal = lamb_opt['lambda']\n",
    "lamb_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metric_test = np.mean(df_lam['metric'], axis=0)\n",
    "mean_metric_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7c96f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lam_tra = pd.DataFrame(training_scores, columns=['metric'])\n",
    "mean_metric_tra = np.mean(df_lam_tra['metric'], axis=0)\n",
    "mean_metric_tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f939e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = np.array(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc33a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a numpy array 'lambdas' containing your lambda values\n",
    "# and 'coefficients' is a numpy array with shape (number_of_lambda_values, number_of_features)\n",
    "# You want to plot coefficients for the first 20 lambdas\n",
    "\n",
    "# Plot lambda-coefficient graph for all coefficients on the same graph\n",
    "for feature_index in range(coefficients.shape[1]):\n",
    "    plt.plot(lambdas[:l_num], coefficients[:l_num, feature_index], label=f'Valor del coeficiente {feature_index}')\n",
    "\n",
    "    # Add a vertical line at x = 16.2\n",
    "plt.axvline(x=lambda_optimal, color='red', linestyle='--', label='Vertical Line at x=16.2')\n",
    "\n",
    "plt.xlabel('Valor del lambda')\n",
    "plt.ylabel('Valor del coeficiente')\n",
    "plt.title('Los coeficientes a lo largo de los valores de los lambdas')\n",
    "plt.grid(True)\n",
    "# plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.savefig('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\4_grafico\\\\coeficiente_lambda_1_completo_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2782daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dataframe= pd.DataFrame(coefficients)\n",
    "coef_lambda = pd.concat([coef_dataframe, df_lam], axis=1)\n",
    "filtered_coef_df = coef_lambda[coef_lambda['lambda'] == lambda_optimal]\n",
    "\n",
    "columns_to_drop = ['metric', 'lambda']\n",
    "filtered_coef_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "non_zero_values = filtered_coef_df.iloc[0].sort_values()\n",
    "non_zero_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab076d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value_coef=0.1\n",
    "\n",
    "non_zero_variable_names = non_zero_values[non_zero_values.abs() > min_value_coef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66059c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nzvn = non_zero_values[non_zero_values.abs() > min_value_coef].index.tolist()\n",
    "nzvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d150bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns by index\n",
    "selected_columns = x_test.iloc[:, nzvn]\n",
    "\n",
    "#export data\n",
    "# Export Y DataFrame to CSV\n",
    "selected_columns.to_csv('G://Mi unidad//PUCP//2021-2//TESIS_1//3_datos//test_data_var_1.csv', index=False)\n",
    "selected_columns \n",
    "#all the values that this varaibles take "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70947fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_info_list = list(zip(selected_columns.columns, nzvn))\n",
    "column_info_df = pd.DataFrame(column_info_list, columns=['ColumnName', 'NZVN'])\n",
    "\n",
    "m_values_columns = pd.merge(column_info_df, non_zero_values, left_on='NZVN', right_index=True)\n",
    "m_values_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88769c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_values = non_zero_values.abs().sort_values()\n",
    "nzvn_10 = absolute_values.tail(10).index.tolist()\n",
    "\n",
    "# Select columns by index\n",
    "selected_columns_10 = x_test.iloc[:, nzvn_10]\n",
    "\n",
    "#export data\n",
    "# Export Y DataFrame to CSV\n",
    "selected_columns_10.to_csv('G://Mi unidad//PUCP//2021-2//TESIS_1//3_datos//test_data_var_1_10.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_info_list_10 = list(zip(selected_columns_10.columns, nzvn_10))\n",
    "column_info_df_10 = pd.DataFrame(column_info_list_10, columns=['ColumnName', 'NZVN'])\n",
    "\n",
    "m_values_columns_10 = pd.merge(column_info_df_10, absolute_values, left_on='NZVN', right_index=True)\n",
    "m_values_columns_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ca026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7aa19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming you have a numpy array 'lambdas' containing your lambda values\n",
    "# # and 'coefficients' is a numpy array with shape (number_of_lambda_values, number_of_features)\n",
    "# # You want to plot coefficients for the first 20 lambdas\n",
    "\n",
    "# # Plot lambda-coefficient graph for all coefficients on the same graph\n",
    "# for feature_index in range(coefficients.shape[1]):\n",
    "#     plt.plot(lambdas[:l_num_div], coefficients[:l_num_div, feature_index], label=f'Coefficient for Feature {feature_index}')\n",
    "\n",
    "# plt.xlabel('Lambda Values')\n",
    "# plt.ylabel('Coefficient Value')\n",
    "# plt.title('Los coeficientes a lo largo de los valores de los lambdas (del 0 al 5)')\n",
    "# plt.grid(True)\n",
    "# # plt.legend(loc='best')\n",
    "# plt.show()\n",
    "\n",
    "# plt.savefig('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\4_grafico\\\\coeficiente_lambda_1_first_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d35fa8d",
   "metadata": {},
   "source": [
    "## 2. Logit penalizado con SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scores2 = []\n",
    "testing_scores2 = []\n",
    "coefficients2 = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, i in enumerate(lambdas):\n",
    "    # Create a pipeline with RandomUnderSampler and LogisticRegression with L1 penalty\n",
    "    reg2 = pl.make_pipeline(\n",
    "        SMOTE(random_state=your_seed),\n",
    "        LogisticRegression(C=1/i, penalty='l1', solver='liblinear', random_state=your_seed)\n",
    "    )\n",
    "    \n",
    "    reg2.fit(x_train, y_train)\n",
    "    \n",
    "    skf2 = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=your_seed)\n",
    "    results2 = cross_validate(reg2, x_train, y_train, groups=groups, cv=skf2, scoring=\"roc_auc\", return_train_score=True)\n",
    "    \n",
    "    # Append the training and testing score means to the lists\n",
    "    training_scores2.append(results2['train_score'].mean())\n",
    "    testing_scores2.append(results2['test_score'].mean())\n",
    "    \n",
    "    # Capture the coefficients\n",
    "    coefficients2.append(reg2.named_steps['logisticregression'].coef_.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4657f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence intervals\n",
    "\n",
    "# Number of bootstrap samples\n",
    "num_bootstrap_samples = 1000\n",
    "\n",
    "# Initialize an array to store bootstrap samples for \n",
    "bootstrap_samples_test2 = np.zeros((num_bootstrap_samples, len(testing_scores2)))\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(num_bootstrap_samples):\n",
    "    # Resample with replacement\n",
    "    bootstrap_sample_test2 = resample(testing_scores2)\n",
    "    bootstrap_samples_test2[i, :] = bootstrap_sample_test2\n",
    "    \n",
    "\n",
    "# Initialize an array to store bootstrap samples\n",
    "bootstrap_samples_tra2 = np.zeros((num_bootstrap_samples, len(training_scores2)))\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(num_bootstrap_samples):\n",
    "    # Resample with replacement\n",
    "    bootstrap_sample_tra2 = resample(training_scores2)\n",
    "    bootstrap_samples_tra2[i, :] = bootstrap_sample_tra2\n",
    "\n",
    "    \n",
    "\n",
    "# Calculate mean and percentiles for confidence intervals\n",
    "mean_scores_test2 = np.mean(bootstrap_samples_test2, axis=0)\n",
    "lower_bound_test2 = np.percentile(bootstrap_samples_test2, 2.5, axis=0)\n",
    "upper_bound_test2 = np.percentile(bootstrap_samples_test2, 97.5, axis=0)\n",
    "\n",
    "# Calculate mean and percentiles for confidence intervals\n",
    "mean_scores_tra2 = np.mean(bootstrap_samples_tra2, axis=0)\n",
    "lower_bound_tra2 = np.percentile(bootstrap_samples_tra2, 2.5, axis=0)\n",
    "upper_bound_tra2 = np.percentile(bootstrap_samples_tra2, 97.5, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7727b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "\n",
    "#plt.plot(np.std(testing_scores2)+(testing_scores2), 'bo-', label=r'Intervalos de confianza', color=\"darkblue\", marker = \"o\",markersize = 8,  alpha=0.6, linewidth=3)\n",
    "plt.plot(lambdas, testing_scores2, label=r'Muestra de validación', color=\"darkred\", marker = \"o\", markersize=8, alpha=0.6, linewidth=3)\n",
    "#plt.plot((testing_scores2)-np.std(testing_scores2), 'bo-', marker = \"o\", color=\"darkblue\", alpha=0.6, linewidth=3)\n",
    "plt.fill_between(lambdas, lower_bound_test2, upper_bound_test2, color='lightcoral', alpha=0.3)\n",
    "\n",
    "#plt.plot(np.std(training_scores2)+(training_scores2), 'bo-', color=\"darkblue\", marker = \"o\",markersize = 8,  alpha=0.6, linewidth=3)\n",
    "plt.plot(lambdas, training_scores2, label=r'Muestra de entrenamiento', color=\"green\", marker = \"o\", markersize=8, alpha=0.6, linewidth=3)\n",
    "#plt.plot((training_scores2)-np.std(training_scores2), 'bo-', marker = \"o\", color=\"darkblue\", alpha=0.6, linewidth=3)\n",
    "plt.fill_between(lambdas, lower_bound_tra2, upper_bound_tra2, color='lightgreen', alpha=0.3)\n",
    "\n",
    "\n",
    "plt.xlabel('Valor del lambda'); plt.ylabel('Valor promedio de AUC ROC')\n",
    "plt.xlim(0,500)\n",
    "plt.ylim(0.4,0.7)\n",
    "plt.title('Valor promedio del $AUC ROC$ en las muestras de entrenamiento y validación según lambda')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\4_grafico\\\\precision_2_lambda_completo_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hallamos el lambda que maximiza el precision\n",
    "df_lam2 = pd.DataFrame(testing_scores2, columns=['metric'])\n",
    "df_lam2['lambda'] = (lambdas)\n",
    "lamb_opt2 = df_lam2.loc[df_lam2['metric'].idxmax()]\n",
    "lambda_optimal2 = lamb_opt2['lambda']\n",
    "lamb_opt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ebe4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metric_test2 = np.mean(df_lam2['metric'], axis=0)\n",
    "mean_metric_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7405da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lam_tra2 = pd.DataFrame(training_scores2, columns=['metric'])\n",
    "mean_metric_tra2 = np.mean(df_lam_tra2['metric'], axis=0)\n",
    "mean_metric_tra2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac740c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients2 = np.array(coefficients2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fcf12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a numpy array 'lambdas' containing your lambda values\n",
    "# and 'coefficients' is a numpy array with shape (number_of_lambda_values, number_of_features)\n",
    "# You want to plot coefficients for the first 20 lambdas\n",
    "\n",
    "# Plot lambda-coefficient graph for all coefficients on the same graph\n",
    "for feature_index in range(coefficients2.shape[1]):\n",
    "    plt.plot(lambdas[:l_num], coefficients2[:l_num, feature_index], label=f'Valor del coeficiente {feature_index}')\n",
    "\n",
    "    # Add a vertical line at x = 16.2\n",
    "plt.axvline(x=lambda_optimal2, color='red', linestyle='--', label='Vertical Line at x=16.2')\n",
    "\n",
    "plt.xlabel('Valor del lambda')\n",
    "plt.ylabel('Valor del coeficiente')\n",
    "plt.title('Los coeficientes a lo largo de los valores de los lambdas')\n",
    "plt.grid(True)\n",
    "# plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.savefig('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\4_grafico\\\\coeficiente_lambda_2_completo_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d8226",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dataframe2= pd.DataFrame(coefficients2)\n",
    "coef_lambda2 = pd.concat([coef_dataframe2, df_lam2], axis=1)\n",
    "filtered_coef_df2= coef_lambda2[coef_lambda2['lambda'] == lambda_optimal]\n",
    "\n",
    "columns_to_drop = ['metric', 'lambda']\n",
    "filtered_coef_df2.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "non_zero_values2 = filtered_coef_df2.iloc[0].sort_values()\n",
    "non_zero_values2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da142fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value_coef=0.1\n",
    "\n",
    "non_zero_variable_names2 = non_zero_values2[non_zero_values2.abs() > min_value_coef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f949a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "nzvn2 = non_zero_values2[non_zero_values2.abs() > min_value_coef].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns by index\n",
    "selected_columns2 = x_test.iloc[:, nzvn2]\n",
    "#export data\n",
    "# Export Y DataFrame to CSV\n",
    "selected_columns2.to_csv('G://Mi unidad//PUCP//2021-2//TESIS_1//3_datos//test_data_var2_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_info_list2 = list(zip(selected_columns2.columns, nzvn2))\n",
    "column_info_df2 = pd.DataFrame(column_info_list2, columns=['ColumnName', 'NZVN2'])\n",
    "\n",
    "m_values_columns2 = pd.merge(column_info_df2, non_zero_values2, left_on='NZVN2', right_index=True)\n",
    "m_values_columns2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea09f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_values2 = non_zero_values2.abs().sort_values()\n",
    "nzvn_102 = absolute_values2.tail(10).index.tolist()\n",
    "\n",
    "# Select columns by index\n",
    "selected_columns_102 = x_test.iloc[:, nzvn_102]\n",
    "\n",
    "#export data\n",
    "# Export Y DataFrame to CSV\n",
    "selected_columns_102.to_csv('G://Mi unidad//PUCP//2021-2//TESIS_1//3_datos//test_data_var_1_10.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_info_list_102 = list(zip(selected_columns_102.columns, nzvn_102))\n",
    "column_info_df_102 = pd.DataFrame(column_info_list_102, columns=['ColumnName', 'NZVN'])\n",
    "\n",
    "m_values_columns_102 = pd.merge(column_info_df_102, absolute_values2, left_on='NZVN', right_index=True)\n",
    "m_values_columns_102"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d477a6c",
   "metadata": {},
   "source": [
    "## Estimating the ROC curve with the optimal lamba for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdae547",
   "metadata": {},
   "source": [
    "## 1. Penalized Logit with Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f3950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# # Create the dataset\n",
    "X, Y = make_classification(n_samples=1000000, n_classes=2, weights=[0.89, 0.10], random_state=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2341, random_state=42)  # Use a random state to ensure reproducibility\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "reg = make_pipeline(\n",
    "    RandomUnderSampler(random_state=your_seed),\n",
    "    LogisticRegression(C=1/lambda_optimal, penalty='l1', solver='liblinear', random_state=your_seed)\n",
    ")\n",
    "\n",
    "# Fit the model using the training data\n",
    "reg_log = reg.fit(X_train, Y_train)\n",
    "\n",
    "# Now, you can use the fitted model for prediction or evaluation\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "\n",
    "y_true=Y_test\n",
    "\n",
    "scores = reg_log.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "# ROC\n",
    "low = min(scores)\n",
    "high = max(scores)\n",
    "\n",
    "step = (low+ high)/100\n",
    "\n",
    "thresholds = np.arange(low, high, step)\n",
    "\n",
    "\n",
    "# Assuming y_true and scores are defined\n",
    "fpr, tpr, thresholds = roc_curve(y_true, scores)\n",
    "\n",
    "# Calculate the J statistic for each threshold\n",
    "J = tpr - fpr\n",
    "\n",
    "# Find the index of the maximum J statistic for the optimal threshold\n",
    "optimal_idx = J.argmax()\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Find the index of the threshold closest to 0.5\n",
    "closest_half_idx = np.abs(thresholds - 0.5).argmin()\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "auc = roc_auc_score(y_true, scores)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f' = Área de la curva ROC: {auc:.2f}')\n",
    "plt.plot(fpr[optimal_idx], tpr[optimal_idx], 'ro', label=f' Umbral optimo: {optimal_threshold:.2f}')\n",
    "plt.plot(fpr[closest_half_idx], tpr[closest_half_idx], 'go', label='Umbral: 0.5')\n",
    "\n",
    "# Adding annotations, labels, and legend\n",
    "plt.xlabel('Tasa de falsos positivos')\n",
    "plt.ylabel('Tasa de verdaderos positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Highlight the points with annotations\n",
    "plt.annotate(f'{optimal_threshold:.2f}', (fpr[optimal_idx], tpr[optimal_idx]), textcoords=\"offset points\", xytext=(10,-10), ha='center')\n",
    "plt.annotate('0.5', (fpr[closest_half_idx], tpr[closest_half_idx]), textcoords=\"offset points\", xytext=(10,-10), ha='center')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b4e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553dc15",
   "metadata": {},
   "source": [
    "##  2. Penalized logit with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f2ee00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Create the dataset\n",
    "X, y = make_classification(n_samples=1000000, n_classes=2, weights=[0.89, 0.10], random_state=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2341, random_state=42)  # Use a random state to ensure reproducibility\n",
    "\n",
    "# Create the pipeline\n",
    "reg2 = make_pipeline(\n",
    "    SMOTE(random_state=your_seed),\n",
    "        LogisticRegression(C=1/lambda_optimal2, penalty='l1', solver='liblinear', random_state=your_seed)\n",
    ")\n",
    "\n",
    "# Fit the model using the training data\n",
    "reg2_log = reg2.fit(X_train, Y_train)\n",
    "\n",
    "# Now, you can use the fitted model for prediction or evaluation\n",
    "y_pred2 = reg2.predict(X_test)\n",
    "\n",
    "\n",
    "y_true=Y_test\n",
    "\n",
    "scores2 = reg2_log.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "# ROC\n",
    "low = min(scores2)\n",
    "high = max(scores2)\n",
    "\n",
    "step = (low+ high)/100\n",
    "\n",
    "thresholds = np.arange(low, high, step)\n",
    "# Assuming y_true and scores are defined\n",
    "fpr, tpr, thresholds = roc_curve(y_true, scores2)\n",
    "\n",
    "# Calculate the J statistic for each threshold\n",
    "J = tpr - fpr\n",
    "\n",
    "# Find the index of the maximum J statistic for the optimal threshold\n",
    "optimal_idx = J.argmax()\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Find the index of the threshold closest to 0.5\n",
    "closest_half_idx = np.abs(thresholds - 0.5).argmin()\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "auc = roc_auc_score(y_true, scores2)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f' = Área de la curva ROC: {auc:.2f}')\n",
    "plt.plot(fpr[optimal_idx], tpr[optimal_idx], 'ro', label=f' Umbral optimo:{optimal_threshold:.2f}')\n",
    "plt.plot(fpr[closest_half_idx], tpr[closest_half_idx], 'go', label='Umbral:0.5')\n",
    "\n",
    "# Adding annotations, labels, and legend\n",
    "plt.xlabel('Tasa de falsos positivos')\n",
    "plt.ylabel('Tasa de verdaderos positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Highlight the points with annotations\n",
    "plt.annotate(f'{optimal_threshold:.2f}', (fpr[optimal_idx], tpr[optimal_idx]), textcoords=\"offset points\", xytext=(10,-10), ha='center')\n",
    "plt.annotate('0.5', (fpr[closest_half_idx], tpr[closest_half_idx]), textcoords=\"offset points\", xytext=(10,-10), ha='center')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa8ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93cb6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = min(scores2)\n",
    "high = max(scores2)\n",
    "\n",
    "step = (low+ high)/100\n",
    "\n",
    "thresholds = np.arange(low, high, step)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90fe40a",
   "metadata": {},
   "source": [
    "### 3. Lasso penalizados post-CV usando SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af229c",
   "metadata": {},
   "source": [
    "### 4. Lasso penalizados post-CV usando Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e937591d",
   "metadata": {},
   "source": [
    "# Using the optimal lambda to estimate the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estimating in the method where we estimated train and tested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba2edd",
   "metadata": {},
   "source": [
    "### 1. Logit Penalized using undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d5fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uso de pipeline\n",
    "\n",
    "pipeline_final = pl.make_pipeline(\n",
    "    RandomUnderSampler(random_state=your_seed),\n",
    "    LogisticRegression(C=1/lambda_optimal, penalty='l1', solver='liblinear', random_state=your_seed)\n",
    "    )\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline_final.fit(x_train, y_train)\n",
    "\n",
    "# Predict probabilities for the positive class\n",
    "y_proba = pipeline_final.predict_proba(x_test)[:, 1]  # Selecting probabilities for the positive class\n",
    "\n",
    "# Apply the custom threshold to determine class labels\n",
    "threshold = 0.5\n",
    "y_pred_bal = (y_proba >= threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7893220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_bal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc30800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_labels = [1 if prob[1] >= 0.175 else 0 for prob in y_pred_bal]\n",
    "# predicted_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca4b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the sum of all values in the array\n",
    "# Calculate mean and standard deviation\n",
    "mean = np.mean(y_pred_bal)\n",
    "std_dev = np.std(y_pred_bal, ddof=1)  # ddof=1 for sample standard deviation\n",
    "\n",
    "# Set confidence level and degrees of freedom\n",
    "confidence_level = 0.95\n",
    "degrees_of_freedom = len(y_pred_bal) - 1\n",
    "\n",
    "# Calculate confidence interval\n",
    "confidence_interval = t.interval(confidence_level, degrees_of_freedom, loc=mean, scale=std_dev/np.sqrt(len(y_pred_bal)))\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Confidence Interval:\", confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331cb7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics para dataset imbalanceados\n",
    "classification_rep = classification_report_imbalanced(y_test, y_pred_bal)\n",
    "print(classification_rep)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_bal)\n",
    "print(roc_auc)\n",
    "\n",
    "#metrics para dataset\n",
    "#print(classification_report(y_test, y_pred_bal))\n",
    "\n",
    "#son iguales a pesar de aplicar SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beaa4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the classification report dictionary to a pandas DataFrame\n",
    "# df_classification = pd.DataFrame(classification_rep)\n",
    "\n",
    "# # Add the ROC AUC score as a new row in the DataFrame\n",
    "# df_classification.loc['ROC AUC'] = roc_auc\n",
    "\n",
    "# # Export the DataFrame to an Excel file\n",
    "# df_classification.to_excel('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\4_grafico\\\\classification_results_1_1.xlsx', sheet_name='results')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_bal)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "#pl.matshow(conf_matrix)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "ax.set_xlabel('Valor predicho');ax.set_ylabel('Valor verdadero'); \n",
    "ax.set_title('Matriz de confusion'); \n",
    "#ax.xaxis.set_ticklabels(['Mantiene bienestar', 'Pierde bienestar']); ax.yaxis.set_ticklabels(['Pierde bienestar', 'Mantiene bienestar']);\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a35b86",
   "metadata": {},
   "source": [
    "### 2. Logit Penalized using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dee221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uso de pipeline\n",
    "\n",
    "pipeline = pl.make_pipeline(\n",
    "    SMOTE(random_state=your_seed),\n",
    "    LogisticRegression(C=1/lambda_optimal2, penalty='l1', solver='liblinear', random_state=your_seed)\n",
    "    )\n",
    "#1.822273\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "pipeline_final2.fit(x_train, y_train)\n",
    "\n",
    "# Predict probabilities for the positive class\n",
    "y_proba = pipeline_final2.predict_proba(x_test)[:, 1]  # Selecting probabilities for the positive class\n",
    "\n",
    "# Apply the custom threshold to determine class labels\n",
    "threshold = 0.5\n",
    "y_pred_bal = (y_proba >= threshold).astype(int)\n",
    "\n",
    "# y_pred_bal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684bed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_labels = [1 if prob[1] >= 0.175 else 0 for prob in y_pred_bal]\n",
    "# predicted_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecacc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the sum of all values in the array\n",
    "# Calculate mean and standard deviation\n",
    "mean = np.mean(y_pred_bal)\n",
    "std_dev = np.std(y_pred_bal, ddof=1)  # ddof=1 for sample standard deviation\n",
    "\n",
    "# Set confidence level and degrees of freedom\n",
    "confidence_level = 0.95\n",
    "degrees_of_freedom = len(y_pred_bal) - 1\n",
    "\n",
    "# Calculate confidence interval\n",
    "confidence_interval = t.interval(confidence_level, degrees_of_freedom, loc=mean, scale=std_dev/np.sqrt(len(y_pred_bal)))\n",
    "\n",
    "print(\"Confidence Interval:\", confidence_interval)\n",
    "print(\"Media:\", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#append selected column con coefficients para ver quienes se van"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88543b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#metrics para dataset imbalanceados\n",
    "print(classification_report_imbalanced(y_test, y_pred_bal))\n",
    "print(roc_auc_score(y_test, y_pred_bal))\n",
    "\n",
    "#metrics para dataset\n",
    "#print(classification_report(y_test, y_pred_bal ))\n",
    "\n",
    "#son iguales a pesar de aplicar SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e190fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_bal)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "ax.set_xlabel('Valor predicho');ax.set_ylabel('Valor verdadero'); \n",
    "ax.set_title('Matriz de confusion'); \n",
    "#ax.xaxis.set_ticklabels(['Mantiene bienestar', 'Pierde bienestar']); ax.yaxis.set_ticklabels(['Pierde bienestar', 'Mantiene bienestar']);\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b1a146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a91b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396442c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb343acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
