{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e36991f",
   "metadata": {},
   "source": [
    "# Thesis project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcfdec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas openpyxl\n",
    "# !pip install graphviz pretty_confusion_matrix pydotplus shap kneed\n",
    "# !pip install scikit-learn==1.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445d515c",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "007196c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }a\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }a\n",
    "</style>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75445578",
   "metadata": {},
   "outputs": [],
   "source": [
    "1#general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statistics\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.stats import t\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22c646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages for Lasso & Data Splitting\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "300915ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pylab as pyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658f75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant packages for \n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9906771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import  confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6c94445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c53e4b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn import pipeline as pl \n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ad9bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6acd0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a289d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import StratifiedGroupKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "007c6211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# from pretty_confusion_matrix import pp_matrix_from_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae4f6ef",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86b727fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Y DataFrame from CSV\n",
    "data_Y_s= pd.read_csv('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\3_datos\\\\data_Y_s_271223_1.csv')\n",
    "\n",
    "# Import X DataFrame from CSV\n",
    "data_m = pd.read_csv('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\3_datos\\\\data_m_271223_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0297bf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each value in 'deg_desemp':\n",
      "0    76.569152\n",
      "1    23.430848\n",
      "Name: ano_19, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming data_Y_s is a pandas DataFrame and deg_desempleo is a column in that DataFrame\n",
    "value_counts_percent = data_Y_s['ano_19'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Percentage of each value in 'deg_desemp':\")\n",
    "print(value_counts_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea571397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_Y_s=data_Y_s1[:1000]\n",
    "# data_m=data_m1[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be37ef8",
   "metadata": {},
   "source": [
    "**Pregunta: i) deberia exportar la matriz de correlacion? o por partes (si alcanza tiempo)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2d15ad",
   "metadata": {},
   "source": [
    "## CV Stratified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e4939b",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57a0ba6",
   "metadata": {},
   "source": [
    "Here, we split the observations in 2 samples: the training set and the test set. Let's remember that our test set is composed from data collected between 2016 to 2019, and we are going test on a data set componsed of a little bit of each year. However, we are going to predict in 2020 and compare with what really happened. \n",
    "\n",
    "To begin with, we must create the X and y that are going to pass throught data splitting into training and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "646e8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_main_pre =  data_m.drop(['num_panel'], axis=1)\n",
    "y_main_pre = data_Y_s.loc[:,('deg_desemp', 'ano_19')]\n",
    "groups_pre = data_m[['ano_reg', 'ano_19']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "472de99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p203a</th>\n",
       "      <th>p558e6</th>\n",
       "      <th>p204</th>\n",
       "      <th>p208a</th>\n",
       "      <th>p209</th>\n",
       "      <th>p306</th>\n",
       "      <th>p314a</th>\n",
       "      <th>p401c</th>\n",
       "      <th>p401f</th>\n",
       "      <th>p401h1</th>\n",
       "      <th>...</th>\n",
       "      <th>ciiu_6c_1</th>\n",
       "      <th>p300a_1.0</th>\n",
       "      <th>ano_16</th>\n",
       "      <th>ano_17</th>\n",
       "      <th>ano_18</th>\n",
       "      <th>ano_19</th>\n",
       "      <th>regnat_1</th>\n",
       "      <th>regnat_2</th>\n",
       "      <th>regnat_3</th>\n",
       "      <th>ano_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.560127</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18317</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18318</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18319</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18320</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18321</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.560127</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18322 rows × 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p203a  p558e6  p204      p208a  p209  p306  p314a  p401c  p401f  \\\n",
       "0        1.0     6.0     1  37.560127     2   0.0    0.0    1.0    1.0   \n",
       "1        1.0     6.0     1  41.000000     5   0.0    0.0    1.0    1.0   \n",
       "2        1.0     6.0     1  42.000000     5   0.0    0.0    1.0    1.0   \n",
       "3        1.0     0.0     1  37.000000     1   0.0    1.0    1.0    1.0   \n",
       "4        1.0     6.0     1  51.000000     1   0.0    0.0    1.0    1.0   \n",
       "...      ...     ...   ...        ...   ...   ...    ...    ...    ...   \n",
       "18317    1.0     0.0     1  35.000000     1   0.0    0.0    1.0    1.0   \n",
       "18318    1.0     6.0     1  37.000000     1   0.0    0.0    1.0    1.0   \n",
       "18319    1.0     6.0     1  43.000000     2   0.0    0.0    1.0    1.0   \n",
       "18320    1.0     6.0     1  44.000000     2   0.0    0.0    1.0    1.0   \n",
       "18321    1.0     6.0     1  37.560127     2   0.0    0.0    1.0    1.0   \n",
       "\n",
       "       p401h1  ...  ciiu_6c_1  p300a_1.0  ano_16  ano_17  ano_18  ano_19  \\\n",
       "0         0.0  ...          1          1       1       0       0       0   \n",
       "1         0.0  ...          1          0       1       0       0       0   \n",
       "2         0.0  ...          0          0       0       0       1       0   \n",
       "3         0.0  ...          0          0       0       1       0       0   \n",
       "4         0.0  ...          0          1       1       0       0       0   \n",
       "...       ...  ...        ...        ...     ...     ...     ...     ...   \n",
       "18317     0.0  ...          1          0       1       0       0       0   \n",
       "18318     0.0  ...          1          0       0       0       1       0   \n",
       "18319     0.0  ...          0          0       1       0       0       0   \n",
       "18320     0.0  ...          1          0       0       0       1       0   \n",
       "18321     0.0  ...          0          0       1       0       0       0   \n",
       "\n",
       "       regnat_1  regnat_2  regnat_3  ano_reg  \n",
       "0             0         1         0        2  \n",
       "1             0         1         0        2  \n",
       "2             0         1         0        8  \n",
       "3             0         1         0        5  \n",
       "4             0         1         0        2  \n",
       "...         ...       ...       ...      ...  \n",
       "18317         0         1         0        2  \n",
       "18318         0         1         0        8  \n",
       "18319         0         1         0        2  \n",
       "18320         0         1         0        8  \n",
       "18321         0         1         0        2  \n",
       "\n",
       "[18322 rows x 220 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_main_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "751a1c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an empty list to store the names of continuous variables\n",
    "# continuous_cols = []\n",
    "\n",
    "# # Set a threshold for the number of unique values to distinguish categorical from continuous variables\n",
    "# unique_value_threshold = 8\n",
    "\n",
    "# # Iterate through the columns and identify continuous variables\n",
    "# for col in x_main_pre.columns:\n",
    "#     # Check if the column is numeric\n",
    "#     if x_main_pre[col].dtype in [int, float]:\n",
    "#         # Check the number of unique values in the column\n",
    "#         num_unique_values = x_main_pre[col].nunique()\n",
    "        \n",
    "#         # Consider it as continuous only if the number of unique values is above the threshold\n",
    "#         if num_unique_values > unique_value_threshold:\n",
    "#             continuous_cols.append(col)\n",
    "        \n",
    "#         # Print column name and data type\n",
    "#         print(f\"{col}: {x_main_pre[col].dtype}\")\n",
    "\n",
    "# # Now 'continuous_cols' will contain the names of continuous variables in the DataFrame\n",
    "# print(\"Continuous Variables:\", continuous_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3347851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_col_total = [\n",
    "    'y_pri_dep', 'y_pri_indep', 'y_pri', 'y_sec_dep', 'y_sec_ind', 'y_sec', 'y_mkt',\n",
    "    'pobre2', 'gpcm', 'ingtrabw', 'ipcr_0', 'ipcr_1', 'ipcr_2', 'ipcr_3', 'ipcr_4',\n",
    "    'ipcr_5', 'ipcr_6', 'ipcr_7', 'ipcr_8', 'ipcr_9', 'ipcr_10', 'ipcr_11', 'ipcr_12',\n",
    "    'ipcr_13', 'ipcr_14', 'ipcr_15', 'ipcr_16', 'ipcr_17', 'ipcr_18', 'ipcr_19', 'ipcr_20',\n",
    "    'gpgru1', 'gpgru2', 'gpgru3', 'gpgru4', 'gpgru5', 'gpgru6', 'gpgru7', 'gpgru8', 'gpgru9',\n",
    "    'gpgru10', 'p104a', 'i1172_01', 'i1172_02', 'i1173_01', 'i1173_02', 'p208a', 'p512a', 'p513t',\n",
    "    'n_edad_prim', 'n_edad_sec', 'n_edad_esc', 'n_matr_prim', 'n_matr_sec', 'n_matr_esc','p203a'\n",
    "]\n",
    "\n",
    "f_cont_total = list(set(continous_col_total).intersection(x_main_pre.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be0331e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_i = x_main_pre.loc[x_main_pre['ano_19'] != 1].drop(['ano_19'], axis=1)\n",
    "y_train = y_main_pre.loc[y_main_pre['ano_19'] != 1].drop(['ano_19'], axis=1)\n",
    "\n",
    "x_test_i = x_main_pre.loc[x_main_pre['ano_19'] == 1].drop(['ano_19'], axis=1)\n",
    "y_test  = y_main_pre.loc[y_main_pre['ano_19'] == 1].drop(['ano_19'], axis=1)\n",
    "\n",
    "groups = groups_pre.loc[x_main_pre['ano_19'] != 1].drop(['ano_19'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99bfda9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_i['gpgru7'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12c2c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract continuous and non-continuous columns from x_train_i\n",
    "# x_train_continuous = x_train_i[f_cont_total]\n",
    "# x_train_non_continuous = x_train_i.drop(columns=f_cont_total)\n",
    "# x_train_continuous.isnull().sum()\n",
    "# # Scale the continuous columns\n",
    "# std = StandardScaler()\n",
    "\n",
    "# scaled_continuous = pd.DataFrame(std.fit_transform(x_train_continuous))\n",
    "# scaled_continuous                             \n",
    "# #scaled_continuous.isnull().sum()\n",
    "# # Create a new DataFrame with scaled continuous columns and non-continuous columns\n",
    "# x_train = pd.concat([scaled_continuous, x_train_non_continuous], axis=1)\n",
    "# x_train\n",
    "# x_train['gpgru7'].isnull().sum()\n",
    "# duplicated_columns = x_train.columns[x_train.columns.duplicated()]\n",
    "# print(\"Duplicated columns: \", duplicated_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2e1dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(scale(x_train_i), columns=x_train_i.columns)\n",
    "#y_train = pd.DataFrame(scaler.fit_transform(y_train_i), columns=y_train_i.columns)\n",
    "\n",
    "x_test = pd.DataFrame(scale(x_test_i), columns=x_test_i.columns)\n",
    "#y_test  = pd.DataFrame(scaler.fit_transform(y_test_i), columns=y_test_i.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68352c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p203a</th>\n",
       "      <th>p558e6</th>\n",
       "      <th>p204</th>\n",
       "      <th>p208a</th>\n",
       "      <th>p209</th>\n",
       "      <th>p306</th>\n",
       "      <th>p314a</th>\n",
       "      <th>p401c</th>\n",
       "      <th>p401f</th>\n",
       "      <th>p401h1</th>\n",
       "      <th>...</th>\n",
       "      <th>tamahno_1</th>\n",
       "      <th>ciiu_6c_1</th>\n",
       "      <th>p300a_1.0</th>\n",
       "      <th>ano_16</th>\n",
       "      <th>ano_17</th>\n",
       "      <th>ano_18</th>\n",
       "      <th>regnat_1</th>\n",
       "      <th>regnat_2</th>\n",
       "      <th>regnat_3</th>\n",
       "      <th>ano_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.471774</td>\n",
       "      <td>0.791669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025269</td>\n",
       "      <td>-0.609911</td>\n",
       "      <td>-0.336637</td>\n",
       "      <td>-1.070250</td>\n",
       "      <td>0.026439</td>\n",
       "      <td>0.217377</td>\n",
       "      <td>-0.108422</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004214</td>\n",
       "      <td>3.716739</td>\n",
       "      <td>2.892258</td>\n",
       "      <td>1.998575</td>\n",
       "      <td>-0.807481</td>\n",
       "      <td>-0.825182</td>\n",
       "      <td>-1.13565</td>\n",
       "      <td>1.702359</td>\n",
       "      <td>-0.468836</td>\n",
       "      <td>-1.362590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.471774</td>\n",
       "      <td>0.791669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517424</td>\n",
       "      <td>0.855819</td>\n",
       "      <td>-0.336637</td>\n",
       "      <td>-1.070250</td>\n",
       "      <td>0.026439</td>\n",
       "      <td>0.217377</td>\n",
       "      <td>-0.108422</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004214</td>\n",
       "      <td>3.716739</td>\n",
       "      <td>-0.345751</td>\n",
       "      <td>1.998575</td>\n",
       "      <td>-0.807481</td>\n",
       "      <td>-0.825182</td>\n",
       "      <td>-1.13565</td>\n",
       "      <td>1.702359</td>\n",
       "      <td>-0.468836</td>\n",
       "      <td>-1.362590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.471774</td>\n",
       "      <td>0.791669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.675189</td>\n",
       "      <td>0.855819</td>\n",
       "      <td>-0.336637</td>\n",
       "      <td>-1.070250</td>\n",
       "      <td>0.026439</td>\n",
       "      <td>0.217377</td>\n",
       "      <td>-0.108422</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004214</td>\n",
       "      <td>-0.269053</td>\n",
       "      <td>-0.345751</td>\n",
       "      <td>-0.500356</td>\n",
       "      <td>-0.807481</td>\n",
       "      <td>1.211854</td>\n",
       "      <td>-1.13565</td>\n",
       "      <td>1.702359</td>\n",
       "      <td>-0.468836</td>\n",
       "      <td>1.167346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.471774</td>\n",
       "      <td>-1.263155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.113637</td>\n",
       "      <td>-1.098488</td>\n",
       "      <td>-0.336637</td>\n",
       "      <td>0.934361</td>\n",
       "      <td>0.026439</td>\n",
       "      <td>0.217377</td>\n",
       "      <td>-0.108422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.995803</td>\n",
       "      <td>-0.269053</td>\n",
       "      <td>-0.345751</td>\n",
       "      <td>-0.500356</td>\n",
       "      <td>1.238419</td>\n",
       "      <td>-0.825182</td>\n",
       "      <td>-1.13565</td>\n",
       "      <td>1.702359</td>\n",
       "      <td>-0.468836</td>\n",
       "      <td>-0.097622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.471774</td>\n",
       "      <td>0.791669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.095075</td>\n",
       "      <td>-1.098488</td>\n",
       "      <td>-0.336637</td>\n",
       "      <td>-1.070250</td>\n",
       "      <td>0.026439</td>\n",
       "      <td>0.217377</td>\n",
       "      <td>-0.108422</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004214</td>\n",
       "      <td>-0.269053</td>\n",
       "      <td>2.892258</td>\n",
       "      <td>1.998575</td>\n",
       "      <td>-0.807481</td>\n",
       "      <td>-0.825182</td>\n",
       "      <td>-1.13565</td>\n",
       "      <td>1.702359</td>\n",
       "      <td>-0.468836</td>\n",
       "      <td>-1.362590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14024</th>\n",
       "      <td>-0.471774</td>\n",
       "      <td>-1.263155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.429168</td>\n",
       "      <td>-1.098488</td>\n",
       "      <td>-0.336637</td>\n",
       "      <td>-1.070250</td>\n",
       "      <td>0.026439</td>\n",
       "      <td>0.217377</td>\n",
       "      <td>-0.108422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.995803</td>\n",
       "      <td>3.716739</td>\n",
       "      <td>-0.345751</td>\n",
       "      <td>1.998575</td>\n",
       "      <td>-0.807481</td>\n",
       "      <td>-0.825182</td>\n",
       "      <td>-1.13565</td>\n",
       "      <td>1.702359</td>\n",
       "      <td>-0.468836</td>\n",
       "      <td>-1.362590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14025</th>\n",
       "      <td>-0.471774</td>\n",
       "      <td>0.791669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.113637</td>\n",
       "      <td>-1.098488</td>\n",
       "      <td>-0.336637</td>\n",
       "      <td>-1.070250</td>\n",
       "      <td>0.026439</td>\n",
       "      <td>0.217377</td>\n",
       "      <td>-0.108422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.995803</td>\n",
       "      <td>3.716739</td>\n",
       "      <td>-0.345751</td>\n",
       "      <td>-0.500356</td>\n",
       "      <td>-0.807481</td>\n",
       "      <td>1.211854</td>\n",
       "      <td>-1.13565</td>\n",
       "      <td>1.702359</td>\n",
       "      <td>-0.468836</td>\n",
       "      <td>1.167346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14026</th>\n",
       "      <td>-0.471774</td>\n",
       "      <td>0.791669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.832954</td>\n",
       "      <td>-0.609911</td>\n",
       "      <td>-0.336637</td>\n",
       "      <td>-1.070250</td>\n",
       "      <td>0.026439</td>\n",
       "      <td>0.217377</td>\n",
       "      <td>-0.108422</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004214</td>\n",
       "      <td>-0.269053</td>\n",
       "      <td>-0.345751</td>\n",
       "      <td>1.998575</td>\n",
       "      <td>-0.807481</td>\n",
       "      <td>-0.825182</td>\n",
       "      <td>-1.13565</td>\n",
       "      <td>1.702359</td>\n",
       "      <td>-0.468836</td>\n",
       "      <td>-1.362590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14027</th>\n",
       "      <td>-0.471774</td>\n",
       "      <td>0.791669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990719</td>\n",
       "      <td>-0.609911</td>\n",
       "      <td>-0.336637</td>\n",
       "      <td>-1.070250</td>\n",
       "      <td>0.026439</td>\n",
       "      <td>0.217377</td>\n",
       "      <td>-0.108422</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004214</td>\n",
       "      <td>3.716739</td>\n",
       "      <td>-0.345751</td>\n",
       "      <td>-0.500356</td>\n",
       "      <td>-0.807481</td>\n",
       "      <td>1.211854</td>\n",
       "      <td>-1.13565</td>\n",
       "      <td>1.702359</td>\n",
       "      <td>-0.468836</td>\n",
       "      <td>1.167346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14028</th>\n",
       "      <td>-0.471774</td>\n",
       "      <td>0.791669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025269</td>\n",
       "      <td>-0.609911</td>\n",
       "      <td>-0.336637</td>\n",
       "      <td>-1.070250</td>\n",
       "      <td>0.026439</td>\n",
       "      <td>0.217377</td>\n",
       "      <td>-0.108422</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004214</td>\n",
       "      <td>-0.269053</td>\n",
       "      <td>-0.345751</td>\n",
       "      <td>1.998575</td>\n",
       "      <td>-0.807481</td>\n",
       "      <td>-0.825182</td>\n",
       "      <td>-1.13565</td>\n",
       "      <td>1.702359</td>\n",
       "      <td>-0.468836</td>\n",
       "      <td>-1.362590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14029 rows × 219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          p203a    p558e6  p204     p208a      p209      p306     p314a  \\\n",
       "0     -0.471774  0.791669   0.0 -0.025269 -0.609911 -0.336637 -1.070250   \n",
       "1     -0.471774  0.791669   0.0  0.517424  0.855819 -0.336637 -1.070250   \n",
       "2     -0.471774  0.791669   0.0  0.675189  0.855819 -0.336637 -1.070250   \n",
       "3     -0.471774 -1.263155   0.0 -0.113637 -1.098488 -0.336637  0.934361   \n",
       "4     -0.471774  0.791669   0.0  2.095075 -1.098488 -0.336637 -1.070250   \n",
       "...         ...       ...   ...       ...       ...       ...       ...   \n",
       "14024 -0.471774 -1.263155   0.0 -0.429168 -1.098488 -0.336637 -1.070250   \n",
       "14025 -0.471774  0.791669   0.0 -0.113637 -1.098488 -0.336637 -1.070250   \n",
       "14026 -0.471774  0.791669   0.0  0.832954 -0.609911 -0.336637 -1.070250   \n",
       "14027 -0.471774  0.791669   0.0  0.990719 -0.609911 -0.336637 -1.070250   \n",
       "14028 -0.471774  0.791669   0.0 -0.025269 -0.609911 -0.336637 -1.070250   \n",
       "\n",
       "          p401c     p401f    p401h1  ...  tamahno_1  ciiu_6c_1  p300a_1.0  \\\n",
       "0      0.026439  0.217377 -0.108422  ...   1.004214   3.716739   2.892258   \n",
       "1      0.026439  0.217377 -0.108422  ...   1.004214   3.716739  -0.345751   \n",
       "2      0.026439  0.217377 -0.108422  ...   1.004214  -0.269053  -0.345751   \n",
       "3      0.026439  0.217377 -0.108422  ...  -0.995803  -0.269053  -0.345751   \n",
       "4      0.026439  0.217377 -0.108422  ...   1.004214  -0.269053   2.892258   \n",
       "...         ...       ...       ...  ...        ...        ...        ...   \n",
       "14024  0.026439  0.217377 -0.108422  ...  -0.995803   3.716739  -0.345751   \n",
       "14025  0.026439  0.217377 -0.108422  ...  -0.995803   3.716739  -0.345751   \n",
       "14026  0.026439  0.217377 -0.108422  ...   1.004214  -0.269053  -0.345751   \n",
       "14027  0.026439  0.217377 -0.108422  ...   1.004214   3.716739  -0.345751   \n",
       "14028  0.026439  0.217377 -0.108422  ...   1.004214  -0.269053  -0.345751   \n",
       "\n",
       "         ano_16    ano_17    ano_18  regnat_1  regnat_2  regnat_3   ano_reg  \n",
       "0      1.998575 -0.807481 -0.825182  -1.13565  1.702359 -0.468836 -1.362590  \n",
       "1      1.998575 -0.807481 -0.825182  -1.13565  1.702359 -0.468836 -1.362590  \n",
       "2     -0.500356 -0.807481  1.211854  -1.13565  1.702359 -0.468836  1.167346  \n",
       "3     -0.500356  1.238419 -0.825182  -1.13565  1.702359 -0.468836 -0.097622  \n",
       "4      1.998575 -0.807481 -0.825182  -1.13565  1.702359 -0.468836 -1.362590  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "14024  1.998575 -0.807481 -0.825182  -1.13565  1.702359 -0.468836 -1.362590  \n",
       "14025 -0.500356 -0.807481  1.211854  -1.13565  1.702359 -0.468836  1.167346  \n",
       "14026  1.998575 -0.807481 -0.825182  -1.13565  1.702359 -0.468836 -1.362590  \n",
       "14027 -0.500356 -0.807481  1.211854  -1.13565  1.702359 -0.468836  1.167346  \n",
       "14028  1.998575 -0.807481 -0.825182  -1.13565  1.702359 -0.468836 -1.362590  \n",
       "\n",
       "[14029 rows x 219 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57aacbf",
   "metadata": {},
   "source": [
    "Let's remember the train set is going to be used to train the model (by simulating a lot of samples using the CV) and the test set is going to be used to test the model out-of-sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6011fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([x_train, x_test], ignore_index=True)\n",
    "Y = pd.concat([y_train, y_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b247d5",
   "metadata": {},
   "source": [
    "We have 193 variables in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2037ec",
   "metadata": {},
   "source": [
    "For the Stratified Group CV, we need to determine the variable groups that the code will interpret as groups of the x variables and the class will depend on the \"groups\" of y (2 classes: employment and nonemployment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74bfee24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_relativa       0\n",
      "n_edad_prim      0\n",
      "n_edad_esc       0\n",
      "n_matr_prim      0\n",
      "n_matr_sec       0\n",
      "n_matr_esc       0\n",
      "menor_trabaja    0\n",
      "educ_0.0         0\n",
      "educ_1.0         0\n",
      "educ_2.0         0\n",
      "educ_3.0         0\n",
      "educ_4.0         0\n",
      "educ_5.0         0\n",
      "n_edad_sec       0\n",
      "ano_reg          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_counts = x_train.isna().sum().sort_values()\n",
    "n = 15  # Number of last values you want to print\n",
    "last_n_values = missing_counts[-n:]\n",
    "\n",
    "print(last_n_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cde172",
   "metadata": {},
   "source": [
    "## Estimations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38137bcf",
   "metadata": {},
   "source": [
    "### Choosing the optimal lambda using grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa1efd4",
   "metadata": {},
   "source": [
    "We establish a a grid of posibles values for $\\lambda$ using grid search. It starts at the value of 0 and then we started trying with different maximun values, as well as differente intervals between the values (that depend on the number of $\\lambda$ we are planning to incluide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6dd3f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-03, 5.01499499e-01, 1.00199900e+00, 1.50249850e+00,\n",
       "       2.00299800e+00, 2.50349750e+00, 3.00399700e+00, 3.50449650e+00,\n",
       "       4.00499600e+00, 4.50549550e+00, 5.00599499e+00, 5.50649449e+00,\n",
       "       6.00699399e+00, 6.50749349e+00, 7.00799299e+00, 7.50849249e+00,\n",
       "       8.00899199e+00, 8.50949149e+00, 9.00999099e+00, 9.51049049e+00,\n",
       "       1.00109900e+01, 1.05114895e+01, 1.10119890e+01, 1.15124885e+01,\n",
       "       1.20129880e+01, 1.25134875e+01, 1.30139870e+01, 1.35144865e+01,\n",
       "       1.40149860e+01, 1.45154855e+01, 1.50159850e+01, 1.55164845e+01,\n",
       "       1.60169840e+01, 1.65174835e+01, 1.70179830e+01, 1.75184825e+01,\n",
       "       1.80189820e+01, 1.85194815e+01, 1.90199810e+01, 1.95204805e+01,\n",
       "       2.00209800e+01, 2.05214795e+01, 2.10219790e+01, 2.15224785e+01,\n",
       "       2.20229780e+01, 2.25234775e+01, 2.30239770e+01, 2.35244765e+01,\n",
       "       2.40249760e+01, 2.45254755e+01, 2.50259750e+01, 2.55264745e+01,\n",
       "       2.60269740e+01, 2.65274735e+01, 2.70279730e+01, 2.75284725e+01,\n",
       "       2.80289720e+01, 2.85294715e+01, 2.90299710e+01, 2.95304705e+01,\n",
       "       3.00309700e+01, 3.05314695e+01, 3.10319690e+01, 3.15324685e+01,\n",
       "       3.20329680e+01, 3.25334675e+01, 3.30339670e+01, 3.35344665e+01,\n",
       "       3.40349660e+01, 3.45354655e+01, 3.50359650e+01, 3.55364645e+01,\n",
       "       3.60369640e+01, 3.65374635e+01, 3.70379630e+01, 3.75384625e+01,\n",
       "       3.80389620e+01, 3.85394615e+01, 3.90399610e+01, 3.95404605e+01,\n",
       "       4.00409600e+01, 4.05414595e+01, 4.10419590e+01, 4.15424585e+01,\n",
       "       4.20429580e+01, 4.25434575e+01, 4.30439570e+01, 4.35444565e+01,\n",
       "       4.40449560e+01, 4.45454555e+01, 4.50459550e+01, 4.55464545e+01,\n",
       "       4.60469540e+01, 4.65474535e+01, 4.70479530e+01, 4.75484525e+01,\n",
       "       4.80489520e+01, 4.85494515e+01, 4.90499510e+01, 4.95504505e+01,\n",
       "       5.00509499e+01, 5.05514494e+01, 5.10519489e+01, 5.15524484e+01,\n",
       "       5.20529479e+01, 5.25534474e+01, 5.30539469e+01, 5.35544464e+01,\n",
       "       5.40549459e+01, 5.45554454e+01, 5.50559449e+01, 5.55564444e+01,\n",
       "       5.60569439e+01, 5.65574434e+01, 5.70579429e+01, 5.75584424e+01,\n",
       "       5.80589419e+01, 5.85594414e+01, 5.90599409e+01, 5.95604404e+01,\n",
       "       6.00609399e+01, 6.05614394e+01, 6.10619389e+01, 6.15624384e+01,\n",
       "       6.20629379e+01, 6.25634374e+01, 6.30639369e+01, 6.35644364e+01,\n",
       "       6.40649359e+01, 6.45654354e+01, 6.50659349e+01, 6.55664344e+01,\n",
       "       6.60669339e+01, 6.65674334e+01, 6.70679329e+01, 6.75684324e+01,\n",
       "       6.80689319e+01, 6.85694314e+01, 6.90699309e+01, 6.95704304e+01,\n",
       "       7.00709299e+01, 7.05714294e+01, 7.10719289e+01, 7.15724284e+01,\n",
       "       7.20729279e+01, 7.25734274e+01, 7.30739269e+01, 7.35744264e+01,\n",
       "       7.40749259e+01, 7.45754254e+01, 7.50759249e+01, 7.55764244e+01,\n",
       "       7.60769239e+01, 7.65774234e+01, 7.70779229e+01, 7.75784224e+01,\n",
       "       7.80789219e+01, 7.85794214e+01, 7.90799209e+01, 7.95804204e+01,\n",
       "       8.00809199e+01, 8.05814194e+01, 8.10819189e+01, 8.15824184e+01,\n",
       "       8.20829179e+01, 8.25834174e+01, 8.30839169e+01, 8.35844164e+01,\n",
       "       8.40849159e+01, 8.45854154e+01, 8.50859149e+01, 8.55864144e+01,\n",
       "       8.60869139e+01, 8.65874134e+01, 8.70879129e+01, 8.75884124e+01,\n",
       "       8.80889119e+01, 8.85894114e+01, 8.90899109e+01, 8.95904104e+01,\n",
       "       9.00909099e+01, 9.05914094e+01, 9.10919089e+01, 9.15924084e+01,\n",
       "       9.20929079e+01, 9.25934074e+01, 9.30939069e+01, 9.35944064e+01,\n",
       "       9.40949059e+01, 9.45954054e+01, 9.50959049e+01, 9.55964044e+01,\n",
       "       9.60969039e+01, 9.65974034e+01, 9.70979029e+01, 9.75984024e+01,\n",
       "       9.80989019e+01, 9.85994014e+01, 9.90999009e+01, 9.96004004e+01,\n",
       "       1.00100900e+02, 1.00601399e+02, 1.01101899e+02, 1.01602398e+02,\n",
       "       1.02102898e+02, 1.02603397e+02, 1.03103897e+02, 1.03604396e+02,\n",
       "       1.04104896e+02, 1.04605395e+02, 1.05105895e+02, 1.05606394e+02,\n",
       "       1.06106894e+02, 1.06607393e+02, 1.07107893e+02, 1.07608392e+02,\n",
       "       1.08108892e+02, 1.08609391e+02, 1.09109891e+02, 1.09610390e+02,\n",
       "       1.10110890e+02, 1.10611389e+02, 1.11111889e+02, 1.11612388e+02,\n",
       "       1.12112888e+02, 1.12613387e+02, 1.13113887e+02, 1.13614386e+02,\n",
       "       1.14114886e+02, 1.14615385e+02, 1.15115885e+02, 1.15616384e+02,\n",
       "       1.16116884e+02, 1.16617383e+02, 1.17117883e+02, 1.17618382e+02,\n",
       "       1.18118882e+02, 1.18619381e+02, 1.19119881e+02, 1.19620380e+02,\n",
       "       1.20120880e+02, 1.20621379e+02, 1.21121879e+02, 1.21622378e+02,\n",
       "       1.22122878e+02, 1.22623377e+02, 1.23123877e+02, 1.23624376e+02,\n",
       "       1.24124876e+02, 1.24625375e+02, 1.25125875e+02, 1.25626374e+02,\n",
       "       1.26126874e+02, 1.26627373e+02, 1.27127873e+02, 1.27628372e+02,\n",
       "       1.28128872e+02, 1.28629371e+02, 1.29129871e+02, 1.29630370e+02,\n",
       "       1.30130870e+02, 1.30631369e+02, 1.31131869e+02, 1.31632368e+02,\n",
       "       1.32132868e+02, 1.32633367e+02, 1.33133867e+02, 1.33634366e+02,\n",
       "       1.34134866e+02, 1.34635365e+02, 1.35135865e+02, 1.35636364e+02,\n",
       "       1.36136864e+02, 1.36637363e+02, 1.37137863e+02, 1.37638362e+02,\n",
       "       1.38138862e+02, 1.38639361e+02, 1.39139861e+02, 1.39640360e+02,\n",
       "       1.40140860e+02, 1.40641359e+02, 1.41141859e+02, 1.41642358e+02,\n",
       "       1.42142858e+02, 1.42643357e+02, 1.43143857e+02, 1.43644356e+02,\n",
       "       1.44144856e+02, 1.44645355e+02, 1.45145855e+02, 1.45646354e+02,\n",
       "       1.46146854e+02, 1.46647353e+02, 1.47147853e+02, 1.47648352e+02,\n",
       "       1.48148852e+02, 1.48649351e+02, 1.49149851e+02, 1.49650350e+02,\n",
       "       1.50150850e+02, 1.50651349e+02, 1.51151849e+02, 1.51652348e+02,\n",
       "       1.52152848e+02, 1.52653347e+02, 1.53153847e+02, 1.53654346e+02,\n",
       "       1.54154846e+02, 1.54655345e+02, 1.55155845e+02, 1.55656344e+02,\n",
       "       1.56156844e+02, 1.56657343e+02, 1.57157843e+02, 1.57658342e+02,\n",
       "       1.58158842e+02, 1.58659341e+02, 1.59159841e+02, 1.59660340e+02,\n",
       "       1.60160840e+02, 1.60661339e+02, 1.61161839e+02, 1.61662338e+02,\n",
       "       1.62162838e+02, 1.62663337e+02, 1.63163837e+02, 1.63664336e+02,\n",
       "       1.64164836e+02, 1.64665335e+02, 1.65165835e+02, 1.65666334e+02,\n",
       "       1.66166834e+02, 1.66667333e+02, 1.67167833e+02, 1.67668332e+02,\n",
       "       1.68168832e+02, 1.68669331e+02, 1.69169831e+02, 1.69670330e+02,\n",
       "       1.70170830e+02, 1.70671329e+02, 1.71171829e+02, 1.71672328e+02,\n",
       "       1.72172828e+02, 1.72673327e+02, 1.73173827e+02, 1.73674326e+02,\n",
       "       1.74174826e+02, 1.74675325e+02, 1.75175825e+02, 1.75676324e+02,\n",
       "       1.76176824e+02, 1.76677323e+02, 1.77177823e+02, 1.77678322e+02,\n",
       "       1.78178822e+02, 1.78679321e+02, 1.79179821e+02, 1.79680320e+02,\n",
       "       1.80180820e+02, 1.80681319e+02, 1.81181819e+02, 1.81682318e+02,\n",
       "       1.82182818e+02, 1.82683317e+02, 1.83183817e+02, 1.83684316e+02,\n",
       "       1.84184816e+02, 1.84685315e+02, 1.85185815e+02, 1.85686314e+02,\n",
       "       1.86186814e+02, 1.86687313e+02, 1.87187813e+02, 1.87688312e+02,\n",
       "       1.88188812e+02, 1.88689311e+02, 1.89189811e+02, 1.89690310e+02,\n",
       "       1.90190810e+02, 1.90691309e+02, 1.91191809e+02, 1.91692308e+02,\n",
       "       1.92192808e+02, 1.92693307e+02, 1.93193807e+02, 1.93694306e+02,\n",
       "       1.94194806e+02, 1.94695305e+02, 1.95195805e+02, 1.95696304e+02,\n",
       "       1.96196804e+02, 1.96697303e+02, 1.97197803e+02, 1.97698302e+02,\n",
       "       1.98198802e+02, 1.98699301e+02, 1.99199801e+02, 1.99700300e+02,\n",
       "       2.00200800e+02, 2.00701299e+02, 2.01201799e+02, 2.01702298e+02,\n",
       "       2.02202798e+02, 2.02703297e+02, 2.03203797e+02, 2.03704296e+02,\n",
       "       2.04204796e+02, 2.04705295e+02, 2.05205795e+02, 2.05706294e+02,\n",
       "       2.06206794e+02, 2.06707293e+02, 2.07207793e+02, 2.07708292e+02,\n",
       "       2.08208792e+02, 2.08709291e+02, 2.09209791e+02, 2.09710290e+02,\n",
       "       2.10210790e+02, 2.10711289e+02, 2.11211789e+02, 2.11712288e+02,\n",
       "       2.12212788e+02, 2.12713287e+02, 2.13213787e+02, 2.13714286e+02,\n",
       "       2.14214786e+02, 2.14715285e+02, 2.15215785e+02, 2.15716284e+02,\n",
       "       2.16216784e+02, 2.16717283e+02, 2.17217783e+02, 2.17718282e+02,\n",
       "       2.18218782e+02, 2.18719281e+02, 2.19219781e+02, 2.19720280e+02,\n",
       "       2.20220780e+02, 2.20721279e+02, 2.21221779e+02, 2.21722278e+02,\n",
       "       2.22222778e+02, 2.22723277e+02, 2.23223777e+02, 2.23724276e+02,\n",
       "       2.24224776e+02, 2.24725275e+02, 2.25225775e+02, 2.25726274e+02,\n",
       "       2.26226774e+02, 2.26727273e+02, 2.27227773e+02, 2.27728272e+02,\n",
       "       2.28228772e+02, 2.28729271e+02, 2.29229771e+02, 2.29730270e+02,\n",
       "       2.30230770e+02, 2.30731269e+02, 2.31231769e+02, 2.31732268e+02,\n",
       "       2.32232768e+02, 2.32733267e+02, 2.33233767e+02, 2.33734266e+02,\n",
       "       2.34234766e+02, 2.34735265e+02, 2.35235765e+02, 2.35736264e+02,\n",
       "       2.36236764e+02, 2.36737263e+02, 2.37237763e+02, 2.37738262e+02,\n",
       "       2.38238762e+02, 2.38739261e+02, 2.39239761e+02, 2.39740260e+02,\n",
       "       2.40240760e+02, 2.40741259e+02, 2.41241759e+02, 2.41742258e+02,\n",
       "       2.42242758e+02, 2.42743257e+02, 2.43243757e+02, 2.43744256e+02,\n",
       "       2.44244756e+02, 2.44745255e+02, 2.45245755e+02, 2.45746254e+02,\n",
       "       2.46246754e+02, 2.46747253e+02, 2.47247753e+02, 2.47748252e+02,\n",
       "       2.48248752e+02, 2.48749251e+02, 2.49249751e+02, 2.49750250e+02,\n",
       "       2.50250750e+02, 2.50751249e+02, 2.51251749e+02, 2.51752248e+02,\n",
       "       2.52252748e+02, 2.52753247e+02, 2.53253747e+02, 2.53754246e+02,\n",
       "       2.54254746e+02, 2.54755245e+02, 2.55255745e+02, 2.55756244e+02,\n",
       "       2.56256744e+02, 2.56757243e+02, 2.57257743e+02, 2.57758242e+02,\n",
       "       2.58258742e+02, 2.58759241e+02, 2.59259741e+02, 2.59760240e+02,\n",
       "       2.60260740e+02, 2.60761239e+02, 2.61261739e+02, 2.61762238e+02,\n",
       "       2.62262738e+02, 2.62763237e+02, 2.63263737e+02, 2.63764236e+02,\n",
       "       2.64264736e+02, 2.64765235e+02, 2.65265735e+02, 2.65766234e+02,\n",
       "       2.66266734e+02, 2.66767233e+02, 2.67267733e+02, 2.67768232e+02,\n",
       "       2.68268732e+02, 2.68769231e+02, 2.69269731e+02, 2.69770230e+02,\n",
       "       2.70270730e+02, 2.70771229e+02, 2.71271729e+02, 2.71772228e+02,\n",
       "       2.72272728e+02, 2.72773227e+02, 2.73273727e+02, 2.73774226e+02,\n",
       "       2.74274726e+02, 2.74775225e+02, 2.75275725e+02, 2.75776224e+02,\n",
       "       2.76276724e+02, 2.76777223e+02, 2.77277723e+02, 2.77778222e+02,\n",
       "       2.78278722e+02, 2.78779221e+02, 2.79279721e+02, 2.79780220e+02,\n",
       "       2.80280720e+02, 2.80781219e+02, 2.81281719e+02, 2.81782218e+02,\n",
       "       2.82282718e+02, 2.82783217e+02, 2.83283717e+02, 2.83784216e+02,\n",
       "       2.84284716e+02, 2.84785215e+02, 2.85285715e+02, 2.85786214e+02,\n",
       "       2.86286714e+02, 2.86787213e+02, 2.87287713e+02, 2.87788212e+02,\n",
       "       2.88288712e+02, 2.88789211e+02, 2.89289711e+02, 2.89790210e+02,\n",
       "       2.90290710e+02, 2.90791209e+02, 2.91291709e+02, 2.91792208e+02,\n",
       "       2.92292708e+02, 2.92793207e+02, 2.93293707e+02, 2.93794206e+02,\n",
       "       2.94294706e+02, 2.94795205e+02, 2.95295705e+02, 2.95796204e+02,\n",
       "       2.96296704e+02, 2.96797203e+02, 2.97297703e+02, 2.97798202e+02,\n",
       "       2.98298702e+02, 2.98799201e+02, 2.99299701e+02, 2.99800200e+02,\n",
       "       3.00300700e+02, 3.00801199e+02, 3.01301699e+02, 3.01802198e+02,\n",
       "       3.02302698e+02, 3.02803197e+02, 3.03303697e+02, 3.03804196e+02,\n",
       "       3.04304696e+02, 3.04805195e+02, 3.05305695e+02, 3.05806194e+02,\n",
       "       3.06306694e+02, 3.06807193e+02, 3.07307693e+02, 3.07808192e+02,\n",
       "       3.08308692e+02, 3.08809191e+02, 3.09309691e+02, 3.09810190e+02,\n",
       "       3.10310690e+02, 3.10811189e+02, 3.11311689e+02, 3.11812188e+02,\n",
       "       3.12312688e+02, 3.12813187e+02, 3.13313687e+02, 3.13814186e+02,\n",
       "       3.14314686e+02, 3.14815185e+02, 3.15315685e+02, 3.15816184e+02,\n",
       "       3.16316684e+02, 3.16817183e+02, 3.17317683e+02, 3.17818182e+02,\n",
       "       3.18318682e+02, 3.18819181e+02, 3.19319681e+02, 3.19820180e+02,\n",
       "       3.20320680e+02, 3.20821179e+02, 3.21321679e+02, 3.21822178e+02,\n",
       "       3.22322678e+02, 3.22823177e+02, 3.23323677e+02, 3.23824176e+02,\n",
       "       3.24324676e+02, 3.24825175e+02, 3.25325675e+02, 3.25826174e+02,\n",
       "       3.26326674e+02, 3.26827173e+02, 3.27327673e+02, 3.27828172e+02,\n",
       "       3.28328672e+02, 3.28829171e+02, 3.29329671e+02, 3.29830170e+02,\n",
       "       3.30330670e+02, 3.30831169e+02, 3.31331669e+02, 3.31832168e+02,\n",
       "       3.32332668e+02, 3.32833167e+02, 3.33333667e+02, 3.33834166e+02,\n",
       "       3.34334666e+02, 3.34835165e+02, 3.35335665e+02, 3.35836164e+02,\n",
       "       3.36336664e+02, 3.36837163e+02, 3.37337663e+02, 3.37838162e+02,\n",
       "       3.38338662e+02, 3.38839161e+02, 3.39339661e+02, 3.39840160e+02,\n",
       "       3.40340660e+02, 3.40841159e+02, 3.41341659e+02, 3.41842158e+02,\n",
       "       3.42342658e+02, 3.42843157e+02, 3.43343657e+02, 3.43844156e+02,\n",
       "       3.44344656e+02, 3.44845155e+02, 3.45345655e+02, 3.45846154e+02,\n",
       "       3.46346654e+02, 3.46847153e+02, 3.47347653e+02, 3.47848152e+02,\n",
       "       3.48348652e+02, 3.48849151e+02, 3.49349651e+02, 3.49850150e+02,\n",
       "       3.50350650e+02, 3.50851149e+02, 3.51351649e+02, 3.51852148e+02,\n",
       "       3.52352648e+02, 3.52853147e+02, 3.53353647e+02, 3.53854146e+02,\n",
       "       3.54354646e+02, 3.54855145e+02, 3.55355645e+02, 3.55856144e+02,\n",
       "       3.56356644e+02, 3.56857143e+02, 3.57357643e+02, 3.57858142e+02,\n",
       "       3.58358642e+02, 3.58859141e+02, 3.59359641e+02, 3.59860140e+02,\n",
       "       3.60360640e+02, 3.60861139e+02, 3.61361639e+02, 3.61862138e+02,\n",
       "       3.62362638e+02, 3.62863137e+02, 3.63363637e+02, 3.63864136e+02,\n",
       "       3.64364636e+02, 3.64865135e+02, 3.65365635e+02, 3.65866134e+02,\n",
       "       3.66366634e+02, 3.66867133e+02, 3.67367633e+02, 3.67868132e+02,\n",
       "       3.68368632e+02, 3.68869131e+02, 3.69369631e+02, 3.69870130e+02,\n",
       "       3.70370630e+02, 3.70871129e+02, 3.71371629e+02, 3.71872128e+02,\n",
       "       3.72372628e+02, 3.72873127e+02, 3.73373627e+02, 3.73874126e+02,\n",
       "       3.74374626e+02, 3.74875125e+02, 3.75375625e+02, 3.75876124e+02,\n",
       "       3.76376624e+02, 3.76877123e+02, 3.77377623e+02, 3.77878122e+02,\n",
       "       3.78378622e+02, 3.78879121e+02, 3.79379621e+02, 3.79880120e+02,\n",
       "       3.80380620e+02, 3.80881119e+02, 3.81381619e+02, 3.81882118e+02,\n",
       "       3.82382618e+02, 3.82883117e+02, 3.83383617e+02, 3.83884116e+02,\n",
       "       3.84384616e+02, 3.84885115e+02, 3.85385615e+02, 3.85886114e+02,\n",
       "       3.86386614e+02, 3.86887113e+02, 3.87387613e+02, 3.87888112e+02,\n",
       "       3.88388612e+02, 3.88889111e+02, 3.89389611e+02, 3.89890110e+02,\n",
       "       3.90390610e+02, 3.90891109e+02, 3.91391609e+02, 3.91892108e+02,\n",
       "       3.92392608e+02, 3.92893107e+02, 3.93393607e+02, 3.93894106e+02,\n",
       "       3.94394606e+02, 3.94895105e+02, 3.95395605e+02, 3.95896104e+02,\n",
       "       3.96396604e+02, 3.96897103e+02, 3.97397603e+02, 3.97898102e+02,\n",
       "       3.98398602e+02, 3.98899101e+02, 3.99399601e+02, 3.99900100e+02,\n",
       "       4.00400600e+02, 4.00901099e+02, 4.01401599e+02, 4.01902098e+02,\n",
       "       4.02402598e+02, 4.02903097e+02, 4.03403597e+02, 4.03904096e+02,\n",
       "       4.04404596e+02, 4.04905095e+02, 4.05405595e+02, 4.05906094e+02,\n",
       "       4.06406594e+02, 4.06907093e+02, 4.07407593e+02, 4.07908092e+02,\n",
       "       4.08408592e+02, 4.08909091e+02, 4.09409591e+02, 4.09910090e+02,\n",
       "       4.10410590e+02, 4.10911089e+02, 4.11411589e+02, 4.11912088e+02,\n",
       "       4.12412588e+02, 4.12913087e+02, 4.13413587e+02, 4.13914086e+02,\n",
       "       4.14414586e+02, 4.14915085e+02, 4.15415585e+02, 4.15916084e+02,\n",
       "       4.16416584e+02, 4.16917083e+02, 4.17417583e+02, 4.17918082e+02,\n",
       "       4.18418582e+02, 4.18919081e+02, 4.19419581e+02, 4.19920080e+02,\n",
       "       4.20420580e+02, 4.20921079e+02, 4.21421579e+02, 4.21922078e+02,\n",
       "       4.22422578e+02, 4.22923077e+02, 4.23423577e+02, 4.23924076e+02,\n",
       "       4.24424576e+02, 4.24925075e+02, 4.25425575e+02, 4.25926074e+02,\n",
       "       4.26426574e+02, 4.26927073e+02, 4.27427573e+02, 4.27928072e+02,\n",
       "       4.28428572e+02, 4.28929071e+02, 4.29429571e+02, 4.29930070e+02,\n",
       "       4.30430570e+02, 4.30931069e+02, 4.31431569e+02, 4.31932068e+02,\n",
       "       4.32432568e+02, 4.32933067e+02, 4.33433567e+02, 4.33934066e+02,\n",
       "       4.34434566e+02, 4.34935065e+02, 4.35435565e+02, 4.35936064e+02,\n",
       "       4.36436564e+02, 4.36937063e+02, 4.37437563e+02, 4.37938062e+02,\n",
       "       4.38438562e+02, 4.38939061e+02, 4.39439561e+02, 4.39940060e+02,\n",
       "       4.40440560e+02, 4.40941059e+02, 4.41441559e+02, 4.41942058e+02,\n",
       "       4.42442558e+02, 4.42943057e+02, 4.43443557e+02, 4.43944056e+02,\n",
       "       4.44444556e+02, 4.44945055e+02, 4.45445555e+02, 4.45946054e+02,\n",
       "       4.46446554e+02, 4.46947053e+02, 4.47447553e+02, 4.47948052e+02,\n",
       "       4.48448552e+02, 4.48949051e+02, 4.49449551e+02, 4.49950050e+02,\n",
       "       4.50450550e+02, 4.50951049e+02, 4.51451549e+02, 4.51952048e+02,\n",
       "       4.52452548e+02, 4.52953047e+02, 4.53453547e+02, 4.53954046e+02,\n",
       "       4.54454546e+02, 4.54955045e+02, 4.55455545e+02, 4.55956044e+02,\n",
       "       4.56456544e+02, 4.56957043e+02, 4.57457543e+02, 4.57958042e+02,\n",
       "       4.58458542e+02, 4.58959041e+02, 4.59459541e+02, 4.59960040e+02,\n",
       "       4.60460540e+02, 4.60961039e+02, 4.61461539e+02, 4.61962038e+02,\n",
       "       4.62462538e+02, 4.62963037e+02, 4.63463537e+02, 4.63964036e+02,\n",
       "       4.64464536e+02, 4.64965035e+02, 4.65465535e+02, 4.65966034e+02,\n",
       "       4.66466534e+02, 4.66967033e+02, 4.67467533e+02, 4.67968032e+02,\n",
       "       4.68468532e+02, 4.68969031e+02, 4.69469531e+02, 4.69970030e+02,\n",
       "       4.70470530e+02, 4.70971029e+02, 4.71471529e+02, 4.71972028e+02,\n",
       "       4.72472528e+02, 4.72973027e+02, 4.73473527e+02, 4.73974026e+02,\n",
       "       4.74474526e+02, 4.74975025e+02, 4.75475525e+02, 4.75976024e+02,\n",
       "       4.76476524e+02, 4.76977023e+02, 4.77477523e+02, 4.77978022e+02,\n",
       "       4.78478522e+02, 4.78979021e+02, 4.79479521e+02, 4.79980020e+02,\n",
       "       4.80480520e+02, 4.80981019e+02, 4.81481519e+02, 4.81982018e+02,\n",
       "       4.82482518e+02, 4.82983017e+02, 4.83483517e+02, 4.83984016e+02,\n",
       "       4.84484516e+02, 4.84985015e+02, 4.85485515e+02, 4.85986014e+02,\n",
       "       4.86486514e+02, 4.86987013e+02, 4.87487513e+02, 4.87988012e+02,\n",
       "       4.88488512e+02, 4.88989011e+02, 4.89489511e+02, 4.89990010e+02,\n",
       "       4.90490510e+02, 4.90991009e+02, 4.91491509e+02, 4.91992008e+02,\n",
       "       4.92492508e+02, 4.92993007e+02, 4.93493507e+02, 4.93994006e+02,\n",
       "       4.94494506e+02, 4.94995005e+02, 4.95495505e+02, 4.95996004e+02,\n",
       "       4.96496504e+02, 4.96997003e+02, 4.97497503e+02, 4.97998002e+02,\n",
       "       4.98498502e+02, 4.98999001e+02, 4.99499501e+02, 5.00000000e+02])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#determining a set of lambdas to test wich one is the best\n",
    "l_min = 0.001\n",
    "l_max = 500\n",
    "l_num = 1000\n",
    "l_num_div=np.int(l_num/2)\n",
    "lambdas = np.linspace(l_min,l_max, l_num)\n",
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a4c564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_lambda=np.std(lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf62cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_seed=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1c6636a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_num_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3ae84f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flaml import AutoML\n",
    "# y_train_array = y_train.values\n",
    "# # Define the pipeline with a search space for hyperparameters\n",
    "# def get_pipeline(under_sampler__sampling_strategy, logistic_regression__C):\n",
    "#     return make_pipeline(\n",
    "#         RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42),\n",
    "#         LogisticRegression(C=C, penalty='l1', solver='liblinear', random_state=42)\n",
    "#     )\n",
    "\n",
    "# # Specify the hyperparameter search space\n",
    "# param_space = {\n",
    "#     'under_sampler__sampling_strategy': ('auto', 0.5, 0.8),\n",
    "#     'logistic_regression__C': (0.001, 0.01, 0.1, 1, 10),\n",
    "# }\n",
    "\n",
    "# # Create an AutoML instance\n",
    "# automl = AutoML()\n",
    "\n",
    "# # Run FLAML to search for the best hyperparameters\n",
    "# automl.fit(X_train=x_train, y_train=y_train_array, task='classification', estimator_list=[('pipeline', get_pipeline, param_space)])\n",
    "\n",
    "# # Print the best pipeline configuration and its performance\n",
    "# print(automl.best_estimator)\n",
    "# print(automl.best_config)\n",
    "# print(automl.best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0141706a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deg_desemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   deg_desemp\n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d8826",
   "metadata": {},
   "source": [
    "## 1. Logit penalizado con Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5c5e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scores = []\n",
    "testing_scores = []\n",
    "coefficients = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, i in enumerate(lambdas):\n",
    "    # Create a pipeline with RandomUnderSampler and LogisticRegression with L1 penalty\n",
    "    reg = pl.make_pipeline(\n",
    "        RandomUnderSampler(random_state=your_seed),\n",
    "        LogisticRegression(C=1/i, penalty='l1', solver='liblinear', random_state=your_seed)\n",
    "    )\n",
    "    \n",
    "    reg.fit(x_train, y_train)\n",
    "    \n",
    "    skf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=your_seed)\n",
    "    results = cross_validate(reg, x_train, y_train, groups=groups, cv=skf, scoring=\"roc_auc\", return_train_score=True)\n",
    "    \n",
    "    # Append the training and testing score means to the lists\n",
    "    training_scores.append(results['train_score'].mean())\n",
    "    testing_scores.append(results['test_score'].mean())\n",
    "    \n",
    "    # Capture the coefficients\n",
    "    coefficients.append(reg.named_steps['logisticregression'].coef_.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f37e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence intervals\n",
    "\n",
    "# Number of bootstrap samples\n",
    "num_bootstrap_samples = 1000\n",
    "\n",
    "# Initialize an array to store bootstrap samples for \n",
    "bootstrap_samples_test = np.zeros((num_bootstrap_samples, len(testing_scores)))\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(num_bootstrap_samples):\n",
    "    # Resample with replacement\n",
    "    bootstrap_sample_test = resample(testing_scores)\n",
    "    bootstrap_samples_test[i, :] = bootstrap_sample_test\n",
    "    \n",
    "\n",
    "# Initialize an array to store bootstrap samples\n",
    "bootstrap_samples_tra = np.zeros((num_bootstrap_samples, len(training_scores)))\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(num_bootstrap_samples):\n",
    "    # Resample with replacement\n",
    "    bootstrap_sample_tra = resample(training_scores)\n",
    "    bootstrap_samples_tra[i, :] = bootstrap_sample_tra\n",
    "\n",
    "    \n",
    "\n",
    "# Calculate mean and percentiles for confidence intervals\n",
    "mean_scores_test = np.mean(bootstrap_samples_test, axis=0)\n",
    "lower_bound_test = np.percentile(bootstrap_samples_test, 2.5, axis=0)\n",
    "upper_bound_test = np.percentile(bootstrap_samples_test, 97.5, axis=0)\n",
    "\n",
    "# Calculate mean and percentiles for confidence intervals\n",
    "mean_scores_tra = np.mean(bootstrap_samples_tra, axis=0)\n",
    "lower_bound_tra = np.percentile(bootstrap_samples_tra, 2.5, axis=0)\n",
    "upper_bound_tra = np.percentile(bootstrap_samples_tra, 97.5, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03d0b6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "\n",
    "#plt.plot(np.std(testing_scores)+(testing_scores), 'bo-', label=r'Intervalos de confianza', color=\"darkblue\", marker = \"o\",markersize = 8,  alpha=0.6, linewidth=3)\n",
    "plt.plot(lambdas, testing_scores, label=r'Muestra de validación', color=\"darkred\", marker = \"o\", markersize=8, alpha=0.6, linewidth=3)\n",
    "#plt.plot((testing_scores)-np.std(testing_scores), 'bo-', marker = \"o\", color=\"darkblue\", alpha=0.6, linewidth=3)\n",
    "plt.fill_between(lambdas, lower_bound_test, upper_bound_test, color='lightcoral', alpha=0.3)\n",
    "\n",
    "\n",
    "#plt.plot(np.std(training_scores)+(training_scores), 'bo-', color=\"darkblue\", marker = \"o\",markersize = 8,  alpha=0.6, linewidth=3)\n",
    "plt.plot(lambdas, training_scores, label=r'Muestra de entrenamiento', color=\"green\", marker = \"o\", markersize=8, alpha=0.6, linewidth=3)\n",
    "#plt.plot((training_scores)-np.std(training_scores), 'bo-', marker = \"o\", color=\"darkblue\", alpha=0.6, linewidth=3)\n",
    "plt.fill_between(lambdas, lower_bound_tra, upper_bound_tra, color='lightgreen', alpha=0.3)\n",
    "\n",
    "plt.xlabel('Valor del lambda'); plt.ylabel('Valor promedio de AUC ROC')\n",
    "plt.xlim(0,215)\n",
    "plt.ylim(0.4,0.7)\n",
    "plt.title('Valor promedio del $AUC ROC$ en las muestras de entrenamiento y validación según lambda')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\4_grafico\\\\precision_1_lambda_completo_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hallamos el lambda que maximiza el precision\n",
    "df_lam = pd.DataFrame(testing_scores, columns=['metric'])\n",
    "df_lam['lambda'] = (lambdas)\n",
    "lamb_opt = df_lam.loc[df_lam['metric'].idxmax()]\n",
    "\n",
    "lambda_optimal = lamb_opt['lambda']\n",
    "lamb_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metric_test = np.mean(df_lam['metric'], axis=0)\n",
    "mean_metric_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7c96f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lam_tra = pd.DataFrame(training_scores, columns=['metric'])\n",
    "mean_metric_tra = np.mean(df_lam_tra['metric'], axis=0)\n",
    "mean_metric_tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f939e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = np.array(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc33a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a numpy array 'lambdas' containing your lambda values\n",
    "# and 'coefficients' is a numpy array with shape (number_of_lambda_values, number_of_features)\n",
    "# You want to plot coefficients for the first 20 lambdas\n",
    "\n",
    "# Plot lambda-coefficient graph for all coefficients on the same graph\n",
    "for feature_index in range(coefficients.shape[1]):\n",
    "    plt.plot(lambdas[:l_num], coefficients[:l_num, feature_index], label=f'Valor del coeficiente {feature_index}')\n",
    "\n",
    "    # Add a vertical line at x = 16.2\n",
    "plt.axvline(x=lambda_optimal, color='red', linestyle='--', label='Vertical Line at x=16.2')\n",
    "\n",
    "plt.xlabel('Valor del lambda')\n",
    "plt.ylabel('Valor del coeficiente')\n",
    "plt.title('Los coeficientes a lo largo de los valores de los lambdas')\n",
    "plt.grid(True)\n",
    "# plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.savefig('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\4_grafico\\\\coeficiente_lambda_1_completo_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2782daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dataframe= pd.DataFrame(coefficients)\n",
    "coef_lambda = pd.concat([coef_dataframe, df_lam], axis=1)\n",
    "filtered_coef_df = coef_lambda[coef_lambda['lambda'] == lambda_optimal]\n",
    "\n",
    "columns_to_drop = ['metric', 'lambda']\n",
    "filtered_coef_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "non_zero_values = filtered_coef_df.iloc[0].sort_values()\n",
    "non_zero_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab076d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value_coef=0.1\n",
    "\n",
    "non_zero_variable_names = non_zero_values[non_zero_values.abs() > min_value_coef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66059c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nzvn = non_zero_values[non_zero_values.abs() > min_value_coef].index.tolist()\n",
    "nzvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d150bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns by index\n",
    "selected_columns = x_test.iloc[:, nzvn]\n",
    "\n",
    "#export data\n",
    "# Export Y DataFrame to CSV\n",
    "selected_columns.to_csv('G://Mi unidad//PUCP//2021-2//TESIS_1//3_datos//test_data_var_1.csv', index=False)\n",
    "selected_columns \n",
    "#all the values that this varaibles take "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70947fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_info_list = list(zip(selected_columns.columns, nzvn))\n",
    "column_info_df = pd.DataFrame(column_info_list, columns=['ColumnName', 'NZVN'])\n",
    "\n",
    "m_values_columns = pd.merge(column_info_df, non_zero_values, left_on='NZVN', right_index=True)\n",
    "m_values_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88769c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_values = non_zero_values.abs().sort_values()\n",
    "nzvn_10 = absolute_values.tail(10).index.tolist()\n",
    "\n",
    "# Select columns by index\n",
    "selected_columns_10 = x_test.iloc[:, nzvn_10]\n",
    "\n",
    "#export data\n",
    "# Export Y DataFrame to CSV\n",
    "selected_columns_10.to_csv('G://Mi unidad//PUCP//2021-2//TESIS_1//3_datos//test_data_var_1_10.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_info_list_10 = list(zip(selected_columns_10.columns, nzvn_10))\n",
    "column_info_df_10 = pd.DataFrame(column_info_list_10, columns=['ColumnName', 'NZVN'])\n",
    "\n",
    "m_values_columns_10 = pd.merge(column_info_df_10, absolute_values, left_on='NZVN', right_index=True)\n",
    "m_values_columns_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ca026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7aa19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming you have a numpy array 'lambdas' containing your lambda values\n",
    "# # and 'coefficients' is a numpy array with shape (number_of_lambda_values, number_of_features)\n",
    "# # You want to plot coefficients for the first 20 lambdas\n",
    "\n",
    "# # Plot lambda-coefficient graph for all coefficients on the same graph\n",
    "# for feature_index in range(coefficients.shape[1]):\n",
    "#     plt.plot(lambdas[:l_num_div], coefficients[:l_num_div, feature_index], label=f'Coefficient for Feature {feature_index}')\n",
    "\n",
    "# plt.xlabel('Lambda Values')\n",
    "# plt.ylabel('Coefficient Value')\n",
    "# plt.title('Los coeficientes a lo largo de los valores de los lambdas (del 0 al 5)')\n",
    "# plt.grid(True)\n",
    "# # plt.legend(loc='best')\n",
    "# plt.show()\n",
    "\n",
    "# plt.savefig('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\4_grafico\\\\coeficiente_lambda_1_first_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d35fa8d",
   "metadata": {},
   "source": [
    "## 2. Logit penalizado con SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scores2 = []\n",
    "testing_scores2 = []\n",
    "coefficients2 = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, i in enumerate(lambdas):\n",
    "    # Create a pipeline with RandomUnderSampler and LogisticRegression with L1 penalty\n",
    "    reg2 = pl.make_pipeline(\n",
    "        SMOTE(random_state=your_seed),\n",
    "        LogisticRegression(C=1/i, penalty='l1', solver='liblinear', random_state=your_seed)\n",
    "    )\n",
    "    \n",
    "    reg2.fit(x_train, y_train)\n",
    "    \n",
    "    skf2 = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=your_seed)\n",
    "    results2 = cross_validate(reg2, x_train, y_train, groups=groups, cv=skf2, scoring=\"roc_auc\", return_train_score=True)\n",
    "    \n",
    "    # Append the training and testing score means to the lists\n",
    "    training_scores2.append(results2['train_score'].mean())\n",
    "    testing_scores2.append(results2['test_score'].mean())\n",
    "    \n",
    "    # Capture the coefficients\n",
    "    coefficients2.append(reg2.named_steps['logisticregression'].coef_.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4657f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence intervals\n",
    "\n",
    "# Number of bootstrap samples\n",
    "num_bootstrap_samples = 1000\n",
    "\n",
    "# Initialize an array to store bootstrap samples for \n",
    "bootstrap_samples_test2 = np.zeros((num_bootstrap_samples, len(testing_scores2)))\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(num_bootstrap_samples):\n",
    "    # Resample with replacement\n",
    "    bootstrap_sample_test2 = resample(testing_scores2)\n",
    "    bootstrap_samples_test2[i, :] = bootstrap_sample_test2\n",
    "    \n",
    "\n",
    "# Initialize an array to store bootstrap samples\n",
    "bootstrap_samples_tra2 = np.zeros((num_bootstrap_samples, len(training_scores2)))\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(num_bootstrap_samples):\n",
    "    # Resample with replacement\n",
    "    bootstrap_sample_tra2 = resample(training_scores2)\n",
    "    bootstrap_samples_tra2[i, :] = bootstrap_sample_tra2\n",
    "\n",
    "    \n",
    "\n",
    "# Calculate mean and percentiles for confidence intervals\n",
    "mean_scores_test2 = np.mean(bootstrap_samples_test2, axis=0)\n",
    "lower_bound_test2 = np.percentile(bootstrap_samples_test2, 2.5, axis=0)\n",
    "upper_bound_test2 = np.percentile(bootstrap_samples_test2, 97.5, axis=0)\n",
    "\n",
    "# Calculate mean and percentiles for confidence intervals\n",
    "mean_scores_tra2 = np.mean(bootstrap_samples_tra2, axis=0)\n",
    "lower_bound_tra2 = np.percentile(bootstrap_samples_tra2, 2.5, axis=0)\n",
    "upper_bound_tra2 = np.percentile(bootstrap_samples_tra2, 97.5, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7727b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "\n",
    "#plt.plot(np.std(testing_scores2)+(testing_scores2), 'bo-', label=r'Intervalos de confianza', color=\"darkblue\", marker = \"o\",markersize = 8,  alpha=0.6, linewidth=3)\n",
    "plt.plot(lambdas, testing_scores2, label=r'Muestra de validación', color=\"darkred\", marker = \"o\", markersize=8, alpha=0.6, linewidth=3)\n",
    "#plt.plot((testing_scores2)-np.std(testing_scores2), 'bo-', marker = \"o\", color=\"darkblue\", alpha=0.6, linewidth=3)\n",
    "plt.fill_between(lambdas, lower_bound_test2, upper_bound_test2, color='lightcoral', alpha=0.3)\n",
    "\n",
    "#plt.plot(np.std(training_scores2)+(training_scores2), 'bo-', color=\"darkblue\", marker = \"o\",markersize = 8,  alpha=0.6, linewidth=3)\n",
    "plt.plot(lambdas, training_scores2, label=r'Muestra de entrenamiento', color=\"green\", marker = \"o\", markersize=8, alpha=0.6, linewidth=3)\n",
    "#plt.plot((training_scores2)-np.std(training_scores2), 'bo-', marker = \"o\", color=\"darkblue\", alpha=0.6, linewidth=3)\n",
    "plt.fill_between(lambdas, lower_bound_tra2, upper_bound_tra2, color='lightgreen', alpha=0.3)\n",
    "\n",
    "\n",
    "plt.xlabel('Valor del lambda'); plt.ylabel('Valor promedio de AUC ROC')\n",
    "plt.xlim(0,500)\n",
    "plt.ylim(0.4,0.7)\n",
    "plt.title('Valor promedio del $AUC ROC$ en las muestras de entrenamiento y validación según lambda')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\4_grafico\\\\precision_2_lambda_completo_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hallamos el lambda que maximiza el precision\n",
    "df_lam2 = pd.DataFrame(testing_scores2, columns=['metric'])\n",
    "df_lam2['lambda'] = (lambdas)\n",
    "lamb_opt2 = df_lam2.loc[df_lam2['metric'].idxmax()]\n",
    "lambda_optimal2 = lamb_opt2['lambda']\n",
    "lamb_opt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ebe4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metric_test2 = np.mean(df_lam2['metric'], axis=0)\n",
    "mean_metric_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7405da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lam_tra2 = pd.DataFrame(training_scores2, columns=['metric'])\n",
    "mean_metric_tra2 = np.mean(df_lam_tra2['metric'], axis=0)\n",
    "mean_metric_tra2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac740c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients2 = np.array(coefficients2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fcf12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a numpy array 'lambdas' containing your lambda values\n",
    "# and 'coefficients' is a numpy array with shape (number_of_lambda_values, number_of_features)\n",
    "# You want to plot coefficients for the first 20 lambdas\n",
    "\n",
    "# Plot lambda-coefficient graph for all coefficients on the same graph\n",
    "for feature_index in range(coefficients2.shape[1]):\n",
    "    plt.plot(lambdas[:l_num], coefficients2[:l_num, feature_index], label=f'Valor del coeficiente {feature_index}')\n",
    "\n",
    "    # Add a vertical line at x = 16.2\n",
    "plt.axvline(x=lambda_optimal2, color='red', linestyle='--', label='Vertical Line at x=16.2')\n",
    "\n",
    "plt.xlabel('Valor del lambda')\n",
    "plt.ylabel('Valor del coeficiente')\n",
    "plt.title('Los coeficientes a lo largo de los valores de los lambdas')\n",
    "plt.grid(True)\n",
    "# plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.savefig('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\4_grafico\\\\coeficiente_lambda_2_completo_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d8226",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dataframe2= pd.DataFrame(coefficients2)\n",
    "coef_lambda2 = pd.concat([coef_dataframe2, df_lam2], axis=1)\n",
    "filtered_coef_df2= coef_lambda2[coef_lambda2['lambda'] == lambda_optimal]\n",
    "\n",
    "columns_to_drop = ['metric', 'lambda']\n",
    "filtered_coef_df2.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "non_zero_values2 = filtered_coef_df2.iloc[0].sort_values()\n",
    "non_zero_values2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da142fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value_coef=0.1\n",
    "\n",
    "non_zero_variable_names2 = non_zero_values2[non_zero_values2.abs() > min_value_coef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f949a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "nzvn2 = non_zero_values2[non_zero_values2.abs() > min_value_coef].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns by index\n",
    "selected_columns2 = x_test.iloc[:, nzvn2]\n",
    "#export data\n",
    "# Export Y DataFrame to CSV\n",
    "selected_columns2.to_csv('G://Mi unidad//PUCP//2021-2//TESIS_1//3_datos//test_data_var2_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_info_list2 = list(zip(selected_columns2.columns, nzvn2))\n",
    "column_info_df2 = pd.DataFrame(column_info_list2, columns=['ColumnName', 'NZVN2'])\n",
    "\n",
    "m_values_columns2 = pd.merge(column_info_df2, non_zero_values2, left_on='NZVN2', right_index=True)\n",
    "m_values_columns2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea09f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_values2 = non_zero_values2.abs().sort_values()\n",
    "nzvn_102 = absolute_values2.tail(10).index.tolist()\n",
    "\n",
    "# Select columns by index\n",
    "selected_columns_102 = x_test.iloc[:, nzvn_102]\n",
    "\n",
    "#export data\n",
    "# Export Y DataFrame to CSV\n",
    "selected_columns_102.to_csv('G://Mi unidad//PUCP//2021-2//TESIS_1//3_datos//test_data_var_1_10.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_info_list_102 = list(zip(selected_columns_102.columns, nzvn_102))\n",
    "column_info_df_102 = pd.DataFrame(column_info_list_102, columns=['ColumnName', 'NZVN'])\n",
    "\n",
    "m_values_columns_102 = pd.merge(column_info_df_102, absolute_values2, left_on='NZVN', right_index=True)\n",
    "m_values_columns_102"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d477a6c",
   "metadata": {},
   "source": [
    "## Estimating the ROC curve with the optimal lamba for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdae547",
   "metadata": {},
   "source": [
    "## 1. Penalized Logit with Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f3950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# # Create the dataset\n",
    "X, Y = make_classification(n_samples=1000000, n_classes=2, weights=[0.89, 0.10], random_state=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2341, random_state=42)  # Use a random state to ensure reproducibility\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "reg = make_pipeline(\n",
    "    RandomUnderSampler(random_state=your_seed),\n",
    "    LogisticRegression(C=1/lambda_optimal, penalty='l1', solver='liblinear', random_state=your_seed)\n",
    ")\n",
    "\n",
    "# Fit the model using the training data\n",
    "reg_log = reg.fit(X_train, Y_train)\n",
    "\n",
    "# Now, you can use the fitted model for prediction or evaluation\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "\n",
    "y_true=Y_test\n",
    "\n",
    "scores = reg_log.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "# ROC\n",
    "low = min(scores)\n",
    "high = max(scores)\n",
    "\n",
    "step = (low+ high)/100\n",
    "\n",
    "thresholds = np.arange(low, high, step)\n",
    "\n",
    "\n",
    "# Assuming y_true and scores are defined\n",
    "fpr, tpr, thresholds = roc_curve(y_true, scores)\n",
    "\n",
    "# Calculate the J statistic for each threshold\n",
    "J = tpr - fpr\n",
    "\n",
    "# Find the index of the maximum J statistic for the optimal threshold\n",
    "optimal_idx = J.argmax()\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Find the index of the threshold closest to 0.5\n",
    "closest_half_idx = np.abs(thresholds - 0.5).argmin()\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "auc = roc_auc_score(y_true, scores)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f' = Área de la curva ROC: {auc:.2f}')\n",
    "plt.plot(fpr[optimal_idx], tpr[optimal_idx], 'ro', label=f' Umbral optimo: {optimal_threshold:.2f}')\n",
    "plt.plot(fpr[closest_half_idx], tpr[closest_half_idx], 'go', label='Umbral: 0.5')\n",
    "\n",
    "# Adding annotations, labels, and legend\n",
    "plt.xlabel('Tasa de falsos positivos')\n",
    "plt.ylabel('Tasa de verdaderos positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Highlight the points with annotations\n",
    "plt.annotate(f'{optimal_threshold:.2f}', (fpr[optimal_idx], tpr[optimal_idx]), textcoords=\"offset points\", xytext=(10,-10), ha='center')\n",
    "plt.annotate('0.5', (fpr[closest_half_idx], tpr[closest_half_idx]), textcoords=\"offset points\", xytext=(10,-10), ha='center')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b4e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553dc15",
   "metadata": {},
   "source": [
    "##  2. Penalized logit with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f2ee00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Create the dataset\n",
    "X, y = make_classification(n_samples=1000000, n_classes=2, weights=[0.89, 0.10], random_state=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2341, random_state=42)  # Use a random state to ensure reproducibility\n",
    "\n",
    "# Create the pipeline\n",
    "reg2 = make_pipeline(\n",
    "    SMOTE(random_state=your_seed),\n",
    "        LogisticRegression(C=1/lambda_optimal2, penalty='l1', solver='liblinear', random_state=your_seed)\n",
    ")\n",
    "\n",
    "# Fit the model using the training data\n",
    "reg2_log = reg2.fit(X_train, Y_train)\n",
    "\n",
    "# Now, you can use the fitted model for prediction or evaluation\n",
    "y_pred2 = reg2.predict(X_test)\n",
    "\n",
    "\n",
    "y_true=Y_test\n",
    "\n",
    "scores2 = reg2_log.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "# ROC\n",
    "low = min(scores2)\n",
    "high = max(scores2)\n",
    "\n",
    "step = (low+ high)/100\n",
    "\n",
    "thresholds = np.arange(low, high, step)\n",
    "# Assuming y_true and scores are defined\n",
    "fpr, tpr, thresholds = roc_curve(y_true, scores2)\n",
    "\n",
    "# Calculate the J statistic for each threshold\n",
    "J = tpr - fpr\n",
    "\n",
    "# Find the index of the maximum J statistic for the optimal threshold\n",
    "optimal_idx = J.argmax()\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Find the index of the threshold closest to 0.5\n",
    "closest_half_idx = np.abs(thresholds - 0.5).argmin()\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "auc = roc_auc_score(y_true, scores2)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f' = Área de la curva ROC: {auc:.2f}')\n",
    "plt.plot(fpr[optimal_idx], tpr[optimal_idx], 'ro', label=f' Umbral optimo:{optimal_threshold:.2f}')\n",
    "plt.plot(fpr[closest_half_idx], tpr[closest_half_idx], 'go', label='Umbral:0.5')\n",
    "\n",
    "# Adding annotations, labels, and legend\n",
    "plt.xlabel('Tasa de falsos positivos')\n",
    "plt.ylabel('Tasa de verdaderos positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Highlight the points with annotations\n",
    "plt.annotate(f'{optimal_threshold:.2f}', (fpr[optimal_idx], tpr[optimal_idx]), textcoords=\"offset points\", xytext=(10,-10), ha='center')\n",
    "plt.annotate('0.5', (fpr[closest_half_idx], tpr[closest_half_idx]), textcoords=\"offset points\", xytext=(10,-10), ha='center')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa8ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93cb6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = min(scores2)\n",
    "high = max(scores2)\n",
    "\n",
    "step = (low+ high)/100\n",
    "\n",
    "thresholds = np.arange(low, high, step)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90fe40a",
   "metadata": {},
   "source": [
    "### 3. Lasso penalizados post-CV usando SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af229c",
   "metadata": {},
   "source": [
    "### 4. Lasso penalizados post-CV usando Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e937591d",
   "metadata": {},
   "source": [
    "# Using the optimal lambda to estimate the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estimating in the method where we estimated train and tested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba2edd",
   "metadata": {},
   "source": [
    "### 1. Logit Penalized using undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d5fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uso de pipeline\n",
    "\n",
    "pipeline_final = pl.make_pipeline(\n",
    "    RandomUnderSampler(random_state=your_seed),\n",
    "    LogisticRegression(C=1/lambda_optimal, penalty='l1', solver='liblinear', random_state=your_seed)\n",
    "    )\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline_final.fit(x_train, y_train)\n",
    "\n",
    "# Predict probabilities for the positive class\n",
    "y_proba = pipeline_final.predict_proba(x_test)[:, 1]  # Selecting probabilities for the positive class\n",
    "\n",
    "# Apply the custom threshold to determine class labels\n",
    "threshold = 0.56\n",
    "y_pred_bal = (y_proba >= threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7893220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_bal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc30800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_labels = [1 if prob[1] >= 0.175 else 0 for prob in y_pred_bal]\n",
    "# predicted_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca4b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the sum of all values in the array\n",
    "# Calculate mean and standard deviation\n",
    "mean = np.mean(y_pred_bal)\n",
    "std_dev = np.std(y_pred_bal, ddof=1)  # ddof=1 for sample standard deviation\n",
    "\n",
    "# Set confidence level and degrees of freedom\n",
    "confidence_level = 0.95\n",
    "degrees_of_freedom = len(y_pred_bal) - 1\n",
    "\n",
    "# Calculate confidence interval\n",
    "confidence_interval = t.interval(confidence_level, degrees_of_freedom, loc=mean, scale=std_dev/np.sqrt(len(y_pred_bal)))\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Confidence Interval:\", confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331cb7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics para dataset imbalanceados\n",
    "classification_rep = classification_report_imbalanced(y_test, y_pred_bal)\n",
    "print(classification_rep)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_bal)\n",
    "print(roc_auc)\n",
    "\n",
    "#metrics para dataset\n",
    "#print(classification_report(y_test, y_pred_bal))\n",
    "\n",
    "#son iguales a pesar de aplicar SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beaa4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the classification report dictionary to a pandas DataFrame\n",
    "# df_classification = pd.DataFrame(classification_rep)\n",
    "\n",
    "# # Add the ROC AUC score as a new row in the DataFrame\n",
    "# df_classification.loc['ROC AUC'] = roc_auc\n",
    "\n",
    "# # Export the DataFrame to an Excel file\n",
    "# df_classification.to_excel('G:\\\\Mi unidad\\\\PUCP\\\\2021-2\\\\TESIS_1\\\\4_grafico\\\\classification_results_1_1.xlsx', sheet_name='results')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_bal)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "#pl.matshow(conf_matrix)\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "ax.set_xlabel('Valor predicho');ax.set_ylabel('Valor verdadero'); \n",
    "ax.set_title('Matriz de confusion'); \n",
    "#ax.xaxis.set_ticklabels(['Mantiene bienestar', 'Pierde bienestar']); ax.yaxis.set_ticklabels(['Pierde bienestar', 'Mantiene bienestar']);\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a35b86",
   "metadata": {},
   "source": [
    "### 2. Logit Penalized using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dee221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uso de pipeline\n",
    "\n",
    "pipeline_final2 = pl.make_pipeline(\n",
    "    SMOTE(random_state=your_seed),\n",
    "    LogisticRegression(C=1/lambda_optimal2, penalty='l1', solver='liblinear', random_state=your_seed)\n",
    "    )\n",
    "#1.822273\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "pipeline_final2.fit(x_train, y_train)\n",
    "\n",
    "# Predict probabilities for the positive class\n",
    "y_proba = pipeline_final2.predict_proba(x_test)[:, 1]  # Selecting probabilities for the positive class\n",
    "\n",
    "# Apply the custom threshold to determine class labels\n",
    "threshold = 0.56\n",
    "y_pred_bal = (y_proba >= threshold).astype(int)\n",
    "\n",
    "# y_pred_bal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684bed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_labels = [1 if prob[1] >= 0.175 else 0 for prob in y_pred_bal]\n",
    "# predicted_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecacc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the sum of all values in the array\n",
    "# Calculate mean and standard deviation\n",
    "mean = np.mean(y_pred_bal)\n",
    "std_dev = np.std(y_pred_bal, ddof=1)  # ddof=1 for sample standard deviation\n",
    "\n",
    "# Set confidence level and degrees of freedom\n",
    "confidence_level = 0.95\n",
    "degrees_of_freedom = len(y_pred_bal) - 1\n",
    "\n",
    "# Calculate confidence interval\n",
    "confidence_interval = t.interval(confidence_level, degrees_of_freedom, loc=mean, scale=std_dev/np.sqrt(len(y_pred_bal)))\n",
    "\n",
    "print(\"Confidence Interval:\", confidence_interval)\n",
    "print(\"Media:\", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#append selected column con coefficients para ver quienes se van"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88543b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#metrics para dataset imbalanceados\n",
    "print(classification_report_imbalanced(y_test, y_pred_bal))\n",
    "print(roc_auc_score(y_test, y_pred_bal))\n",
    "\n",
    "#metrics para dataset\n",
    "#print(classification_report(y_test, y_pred_bal ))\n",
    "\n",
    "#son iguales a pesar de aplicar SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e190fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_bal)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "ax.set_xlabel('Valor predicho');ax.set_ylabel('Valor verdadero'); \n",
    "ax.set_title('Matriz de confusion'); \n",
    "#ax.xaxis.set_ticklabels(['Mantiene bienestar', 'Pierde bienestar']); ax.yaxis.set_ticklabels(['Pierde bienestar', 'Mantiene bienestar']);\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b1a146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a91b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396442c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb343acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
